{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\model.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/model.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/model.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/model.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/model.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Importieren der benÃ¶tigten Bibliotheken\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import seaborn as sns\n",
    "import warnings \n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from tqdm.notebook import tqdm \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pfad zur CSV-Datei\n",
    "csv_path = 'C:/Users/busse/CICDPipeline/BA-CICD-Pipeline/model/gender.csv'\n",
    "\n",
    "# Laden der CSV-Datei in einen DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "print(len(df))\n",
    "# Konvertierung der Werte aus der Spalte 'gender' in ein Array\n",
    "gender_labels = df['Male'].values\n",
    "len(gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'C:/Users/busse/CICDPipeline/BA-CICD-Pipeline/data/img_align_celeba/'\n",
    "image_paths = []\n",
    "image_filenames = os.listdir(BASE_DIR)\n",
    "\n",
    "for image in tqdm(image_filenames):\n",
    "  image_path = os.path.join(BASE_DIR, image)\n",
    "  image_paths.append(image_path)\n",
    "\n",
    "\n",
    "image_paths.pop()\n",
    "\n",
    "len(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame({'Images':image_paths, 'Gender': gender_labels})\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = df.iloc[0]\n",
    "\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_df = df.drop(\"Gender\", axis=1)\n",
    "\n",
    "i = 0\n",
    "while i != 10: \n",
    "    img = Image.open(image_df.iloc[i][0])\n",
    "    display(img)\n",
    "    i += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df[\"Gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import warning\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def find_file(filename, directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "    return None\n",
    "\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "n = 2000\n",
    "\n",
    "directory = 'C:/Users/busse/CICDPipeline/BA-CICD-Pipeline/model'\n",
    "filename = f'trained_{n}_model.h5'  \n",
    "file_path = find_file(filename, directory)\n",
    "# file_name = os.path.basename(file_path)  \n",
    "\n",
    "\n",
    "# if file_name == filename:\n",
    "#     print(f'Fehler: Die Datei {filename} ist bereits vorhanden! : {file_path}')\n",
    "\n",
    "#     raise StopExecution()\n",
    "\n",
    "    \n",
    "# if file_path is None:\n",
    "#     print(f'Die Datei {filename} wurde nicht gefunden.')\n",
    "# else:\n",
    "#     print(f'Die Datei {filename} wurde gefunden unter: {file_path}')\n",
    "\n",
    "print(n)\n",
    "df_sample = df.groupby('Gender', group_keys=False).apply(lambda x: x.sample(n=n, random_state=42))\n",
    "sns.displot(df_sample[\"Gender\"])\n",
    "df_sample\n",
    "\n",
    "df_sample = df_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_sample.to_excel(f'Gender_{n}.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "def extract_image_features(images):\n",
    "    features = list()\n",
    "\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        \n",
    "        img = img.resize((178, 218), Image.LANCZOS)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 178, 218, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_image_features(df_sample['Images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape\n",
    "\n",
    "\n",
    "# np.save('features.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Pfad zum Ordner mit den Bildern\n",
    "path = 'C:/Users/busse/CICDPipeline/BA-CICD-Pipeline/data/img_align_celeba'\n",
    "\n",
    "# Pfad zum Zielordner\n",
    "destination = 'C:/Users/busse/OneDrive/Desktop/TestPY'\n",
    "\n",
    "# Liste aller Dateien im Ordner\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Schleife zum Kopieren jeder Datei\n",
    "for i, file in enumerate(files):\n",
    "    if i >= 10000:\n",
    "        break\n",
    "    # Pfad zur aktuellen Datei\n",
    "    current_file_path = os.path.join(path, file)\n",
    "    # Pfad zur neuen Datei\n",
    "    new_file_path = os.path.join(destination, file)\n",
    "    # Kopieren der Datei\n",
    "    shutil.copy(current_file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_X = np.load('features.npy')\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_gender = np.array(df_sample['Gender'])\n",
    "\n",
    "len(y_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class MyCallback(Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if val_acc is not None and val_acc >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "            # Save the model\n",
    "            self.model.save(f'{n}.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X is your feature set and y_gender is your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_gender, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "input_shape = (178, 218, 1)\n",
    "inputs = Input((input_shape))\n",
    "conv_1 = Conv2D(32, kernel_size=(4, 4), activation='relu')(inputs)\n",
    "max_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
    "conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(max_1)\n",
    "max_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
    "conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu')(max_2)\n",
    "max_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n",
    "conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu')(max_3)\n",
    "max_4 = MaxPooling2D(pool_size=(2, 2))(conv_4)\n",
    "\n",
    "flatten = Flatten()(max_4)\n",
    "\n",
    "# fully connected layers\n",
    "dense_1 = Dense(256, activation='relu')(flatten)\n",
    "# dense_2 = Dense(256, activation='relu')(flatten)\n",
    "\n",
    "dropout_1 = Dropout(0.3)(dense_1)\n",
    "# dropout_2 = Dropout(0.3)(dense_2)\n",
    "\n",
    "output_1 = Dense(1, activation='sigmoid', name='gender_out')(dropout_1)\n",
    "\n",
    "# output = Dense(1, activation='sigmoid')(flatten)\n",
    "model = Model(inputs=[inputs], outputs=[output_1])\n",
    "# model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "model.compile(loss=['binary_crossentropy', 'mae'],optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train))\n",
    "print(len(X_train))\n",
    "\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    period=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train, y=y_train,batch_size=32, epochs=30, validation_data=(X_test,y_test),callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"trained_{n}_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model(f'trained_{n}_model.h5')\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Accuracy: {accuracy * 100}')\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "img = load_img('C:/Users/busse/CICDPipeline/BA-CICD-Pipeline/data/test_images/w6.jpg', target_size=(178, 218), color_mode=\"grayscale\")\n",
    "\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "predictions = loaded_model.predict(img_array)\n",
    "\n",
    "if predictions[0] < 0.5:\n",
    "    print(f'Frau:{predictions}')\n",
    "else:\n",
    "    print(f'Mann:{predictions}') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
