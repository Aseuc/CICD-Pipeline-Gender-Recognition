{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_men_train =pd.read_csv( r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\excel_sheets\\git_image_paths_val_men.csv\")\n",
    "# df_men_train[\"Images\"] = df_men_train[\"Images\"].str.replace(\"C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/\", \" \")\n",
    "# df_men_train.to_csv(r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\excel_sheets\\git_image_paths_val_men.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Apply the transformation to your dataset\n",
    "train_dataset = datasets.ImageFolder(root='data/train',transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root= 'data/val',transform=transform)\n",
    "df_men_train = pd.read_csv(\"model/excel_sheets/git_image_paths_men.csv\")\n",
    "df_women_train = pd.read_csv(\"model/excel_sheets/git_image_paths_women.csv\")\n",
    "df_women_test = pd.read_csv(\"model/excel_sheets/git_image_paths_val_women.csv\")\n",
    "df_men_test = pd.read_csv(\"model/excel_sheets/git_image_paths_val_men.csv\")\n",
    "merged_df_train = pd.concat([df_men_train, df_women_train], ignore_index=True)\n",
    "merged_df_test = pd.concat([df_men_test, df_women_test], ignore_index=True)\n",
    "merged_df_test.to_csv(\"model/git_merged_df_test.csv\")\n",
    "merged_df_train.to_csv(\"model/git_merged_df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_data = CustomImageDataset(annotations_file='model/git_merged_df_train.csv',img_dir='data/train')\n",
    "test_data =  CustomImageDataset(annotations_file='model/git_merged_df_test.csv',img_dir='data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "img = train_features[0].permute(1, 2, 0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Erste Convolutional Layer. Nimmt 3 Eingangskanäle (RGB), gibt 6 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=4, Schrittgröße=4\n",
    "        self.pool = nn.MaxPool2d(4, 4)  \n",
    "        # Zweite Convolutional Layer. Nimmt 6 Eingangskanäle (von der vorherigen Schicht), gibt 16 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=2, Schrittgröße=2\n",
    "        self.pool = nn.MaxPool2d(2,2) \n",
    "        # Erste vollständig verbundene Schicht. Nimmt einen abgeflachten Vektor der Größe 33456 auf, gibt einen Vektor der Größe 120 aus\n",
    "        self.fc1 = nn.Linear(33456 , 120) \n",
    "        # Zweite vollständig verbundene Schicht. Nimmt einen Vektor der Größe 120 auf, gibt einen Vektor der Größe 84 aus\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Dritte vollständig verbundene Schicht. Nimmt einen Vektor der Größe 84 auf, gibt einen Vektor der Größe 2 aus\n",
    "        self.fc3 = nn.Linear(84, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Anwendung der ersten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Anwendung der zweiten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Abflachen des Tensorausgangs von den Conv-Schichten\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # Anwendung der ersten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Anwendung der zweiten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        # Anwendung der dritten vollständig verbundenen Schicht\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Assume `val_dataloader` is your DataLoader for the validation set\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "         \n",
    "\n",
    "        # Trainingsverlauf ausgeben\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #Alle 10 Batches wird der Loss ausgegeben\n",
    "        if i % 10 == 9:    \n",
    "            # Berechnung der Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for val_data in test_dataloader:\n",
    "                    val_images, val_labels = val_data\n",
    "                    val_outputs = model(val_images)\n",
    "                    _, predicted = torch.max(val_outputs.data, 1)\n",
    "                    total += val_labels.size(0)\n",
    "                    correct += (predicted == val_labels).sum().item()\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 10}, Validation Accuracy: {val_accuracy * 100}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'model{batch_size}' + '-' + f'{epochs}' + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(f'model{batch_size}.pth'))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for inputs, _ in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    output = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(f'model{batch_size}.pth'))\n",
    "\n",
    "# Assume `test_dataset` is your ImageFolder dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Use the model to make predictions and calculate accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Update total and correct counts\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print('Accuracy of the model on the test images: {}%'.format(100 * accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
