{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_men_train =pd.read_csv( r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\excel_sheets\\git_image_paths_val_men.csv\")\n",
    "# df_men_train[\"Images\"] = df_men_train[\"Images\"].str.replace(\"C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/\", \" \")\n",
    "# df_men_train.to_csv(r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\excel_sheets\\git_image_paths_val_men.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "# img_dir_train ='C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/data/train'\n",
    "# img_dir_val = 'C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/data/val'\n",
    "# train_dataset = datasets.ImageFolder(root=img_dir_train,transform=transform)\n",
    "# test_dataset = datasets.ImageFolder(root= img_dir_val,transform=transform)\n",
    "# Apply the transformation to your dataset\n",
    "train_dataset = datasets.ImageFolder(root='data/train',transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root= 'data/val',transform=transform)\n",
    "df_men_train = pd.read_csv(\"model/excel_sheets/git_image_paths_men.csv\")\n",
    "df_women_train = pd.read_csv(\"model/excel_sheets/git_image_paths_women.csv\")\n",
    "df_women_test = pd.read_csv(\"model/excel_sheets/git_image_paths_val_women.csv\")\n",
    "df_men_test = pd.read_csv(\"model/excel_sheets/git_image_paths_val_men.csv\")\n",
    "merged_df_train = pd.concat([df_men_train, df_women_train], ignore_index=True)\n",
    "merged_df_test = pd.concat([df_men_test, df_women_test], ignore_index=True)\n",
    "merged_df_test.to_csv(\"model/git_merged_df_test.csv\")\n",
    "merged_df_train.to_csv(\"model/git_merged_df_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_data = CustomImageDataset(annotations_file='model/git_merged_df_train.csv',img_dir='data/train')\n",
    "test_data =  CustomImageDataset(annotations_file='model/git_merged_df_test.csv',img_dir='data/val')\n",
    "\n",
    "# train_data = CustomImageDataset(annotations_file='C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/csv_sheets/merged_df_train.csv',img_dir='C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/data/train')\n",
    "# test_data =  CustomImageDataset(annotations_file='C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/model/csv_sheets/merged_df_test.csv',img_dir='C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/data/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "img = train_features[0].permute(1, 2, 0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Erste Convolutional Layer. Nimmt 3 Eingangskanäle (RGB), gibt 6 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=4, Schrittgröße=4\n",
    "        self.pool = nn.MaxPool2d(4, 4)  \n",
    "        # Zweite Convolutional Layer. Nimmt 6 Eingangskanäle (von der vorherigen Schicht), gibt 16 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=2, Schrittgröße=2\n",
    "        self.pool = nn.MaxPool2d(2,2) \n",
    "        # Erste vollständig verbundene Schicht. Nimmt einen abgeflachten Vektor der Größe 33456 auf, gibt einen Vektor der Größe 120 aus\n",
    "        self.fc1 = nn.Linear(33456 , 120) \n",
    "        # Zweite vollständig verbundene Schicht. Nimmt einen Vektor der Größe 120 auf, gibt einen Vektor der Größe 84 aus\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Dritte vollständig verbundene Schicht. Nimmt einen Vektor der Größe 84 auf, gibt einen Vektor der Größe 2 aus\n",
    "        self.fc3 = nn.Linear(84, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Anwendung der ersten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Anwendung der zweiten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Abflachen des Tensorausgangs von den Conv-Schichten\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # Anwendung der ersten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Anwendung der zweiten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        # Anwendung der dritten vollständig verbundenen Schicht\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Instantiate the model, loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Assume `val_dataloader` is your DataLoader for the validation set\n",
    "# for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         inputs, labels = data\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()  \n",
    "         \n",
    "\n",
    "#         # Trainingsverlauf ausgeben\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#         #Alle 10 Batches wird der Loss ausgegeben\n",
    "#         if i % 10 == 9:    \n",
    "#             # Berechnung der Accuracy\n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for val_data in test_dataloader:\n",
    "#                     val_images, val_labels = val_data\n",
    "#                     val_outputs = model(val_images)\n",
    "#                     _, predicted = torch.max(val_outputs.data, 1)\n",
    "#                     total += val_labels.size(0)\n",
    "#                     correct += (predicted == val_labels).sum().item()\n",
    "#             val_accuracy = correct / total\n",
    "\n",
    "#             print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 10}, Validation Accuracy: {val_accuracy * 100}%')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        # Trainingsverlauf ausgeben\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #Alle 10 Batches wird der Loss ausgegeben\n",
    "        if i % 10 == 9:    \n",
    "            # Berechnung der Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for val_data in test_dataloader:\n",
    "                    val_images, val_labels = val_data\n",
    "                    val_outputs = model(val_images)\n",
    "                    _, predicted = torch.max(val_outputs.data, 1)\n",
    "                    total += val_labels.size(0)\n",
    "                    correct += (predicted == val_labels).sum().item()\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 10}, Validation Accuracy: {val_accuracy * 100}%')\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Wenn die Validation Accuracy 95% erreicht, wird das Training beendet\n",
    "            if val_accuracy >= 0.95:\n",
    "                print('Early stopping, validation accuracy reached 95%')\n",
    "                break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path_local = 'C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/'\n",
    "# torch.save(model.state_dict(), f'{model_path_local}model/model{batch_size}' + '-' + f'{epochs}' + '.pth')\n",
    "\n",
    "torch.save(model.state_dict(), f'model/model{batch_size}' + '-' + f'{epochs}' + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'model/model{batch_size}' + '-' + f'{epochs}' + '.pth'\n",
    "# model_path = f'{model_path_local}model/model{batch_size}' + '-' + f'{epochs}' + '.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCNN()\n",
    "# model.load_state_dict(torch.load(f'model/model{batch_size}' + '-' + f'{epochs}' + '.pth'))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for inputs, _ in test_loader:\n",
    "    inputs = inputs.to(device) \n",
    "    output = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = SimpleCNN()\n",
    "# model.load_state_dict(torch.load(f'model/model{batch_size}' + '-' + f'{epochs}' + '.pth'))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# Assume `test_dataset` is your ImageFolder dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Use the model to make predictions and calculate accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Update total and correct counts\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print('Accuracy of the model on the test images: {}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setze das Modell in den Evaluierungsmodus\n",
    "model.eval() \n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted)\n",
    "        true_labels.extend(labels)\n",
    "\n",
    "\n",
    "# Konvertiere die Listen in numpy-Arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Berechne die Metriken\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "\n",
    "with open('metrics.txt', 'w') as outfile:\n",
    "    outfile.write(f'Modellmetriken: Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        # Flatten the outputs and convert to numpy array\n",
    "        predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "# Flatten the arrays\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "\n",
    "# Ensure both arrays have the same length\n",
    "min_length = min(len(predictions), len(labels_list))\n",
    "predictions = predictions[:min_length]\n",
    "labels_list = labels_list[:min_length]\n",
    "\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "\n",
    "# Plot true labels against predictions\n",
    "# plt.scatter(labels_list,predictions)\n",
    "plt.scatter(labels_list,predictions)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "\n",
    "plt.savefig(\"plot_scatter.jpg\",dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot([labels_list.min(), labels_list.max()], [predictions.min(), predictions.max()], 'k--', lw=4)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "plt.savefig(\"plot_plt.jpg\",dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create a 2D histogram from the data\n",
    "heatmap_data, xedges, yedges = np.histogram2d(labels_list, predictions, bins=50)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.imshow(heatmap_data, origin='lower', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Anzahl')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Heatmap of True Labels vs Predictions')\n",
    "plt.savefig(\"heatmap.jpg\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
