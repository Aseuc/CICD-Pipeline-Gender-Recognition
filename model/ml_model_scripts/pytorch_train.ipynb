{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importieren der benötigten Bibliotheken für das ML-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from fairlearn.datasets import fetch_adult\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ML-Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Festlegen der epochen und der Batchsize sowie die Transformierung der Daten in einen Tensor und dann noch normalisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "def count_files(men_dir, women_dir):\n",
    "    men_files = len(os.listdir(men_dir))\n",
    "    women_files = len(os.listdir(women_dir))\n",
    "\n",
    "    total_files = men_files + women_files\n",
    "\n",
    "    print(f\"Anzahl der Dateien in 'men': {men_files}\")\n",
    "    print(f\"Anzahl der Dateien in 'women': {women_files}\")\n",
    "    print(f\"Gesamtanzahl der Dateien: {total_files}\")\n",
    "\n",
    "\n",
    "# Transformation der Daten für das Training und Testen  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((178, 218)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Dateipfade für das Training und Testen festlegen\n",
    "train_dataset = datasets.ImageFolder(root='data/output/train',transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root= 'data/output/val',transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Erstellen eines eigenen Datasets (falls notwendig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "class GenderRecognitionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[idx, 1])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[idx, 2]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image,y_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Überprüfen ob die Bilder richtig angezeigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "img = train_features[0].permute(1, 2, 0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Erstellen eines CNN-Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das CNN-Modell besteht aus 2 Convolutional Layers, 2 Pooling Layers, 2 Max Pooling Layers, 3 Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Erste Convolutional Layer. Nimmt 3 Eingangskanäle (RGB), gibt 6 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=4, Schrittgröße=4\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        # Zweite Convolutional Layer. Nimmt 6 Eingangskanäle (von der vorherigen Schicht), gibt 16 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=2, Schrittgröße=2\n",
    "        self.pool = nn.MaxPool2d(2,2) \n",
    "        # Erste vollständig verbundene Schicht. Nimmt einen abgeflachten Vektor der Größe 33456 auf, gibt einen Vektor der Größe 120 aus\n",
    "        self.fc1 = nn.Linear(33456 , 120) \n",
    "        # Zweite vollständig verbundene Schicht. Nimmt einen Vektor der Größe 120 auf, gibt einen Vektor der Größe 84 aus\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Dritte vollständig verbundene Schicht. Nimmt einen Vektor der Größe 84 auf, gibt einen Vektor der Größe 2 aus\n",
    "        self.fc3 = nn.Linear(84, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Anwendung der ersten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Anwendung der zweiten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Abflachen des Tensorausgangs von den Conv-Schichten\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # Anwendung der ersten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Anwendung der zweiten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        # Anwendung der dritten vollständig verbundenen Schicht\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ML-Modell trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumentation für PyTorch Trainingsskript\n",
    "\n",
    "Dieses Skript trainiert ein Convolutional Neural Network (CNN) mit PyTorch.\n",
    "\n",
    "## Variablen\n",
    "\n",
    "- `model`: Eine Instanz des `SimpleCNN` Modells.\n",
    "- `criterion`: Die Verlustfunktion, die während des Trainings verwendet wird. In diesem Fall wird die Cross-Entropy-Loss-Funktion verwendet.\n",
    "- `optimizer`: Der Optimierer, der zur Aktualisierung der Modellparameter verwendet wird. Hier wird der Stochastic Gradient Descent (SGD) Optimierer verwendet.\n",
    "- `patience`: Die Anzahl der Epochen, die auf eine Verbesserung der Genauigkeit gewartet wird, bevor das Training gestoppt wird.\n",
    "- `best_accuracy`: Die beste Genauigkeit, die während des Trainings erreicht wurde. Initialisiert auf 0.\n",
    "- `early_stopping_counter`: Zählt die Anzahl der Epochen ohne Verbesserung der Genauigkeit.\n",
    "\n",
    "## Trainingsschleife\n",
    "\n",
    "Das Modell wird für eine bestimmte Anzahl von Epochen trainiert. In jeder Epoche wird das Modell mit den Trainingsdaten trainiert und dann mit den Testdaten validiert.\n",
    "\n",
    "Während des Trainings werden die Modellparameter aktualisiert, um den Verlust zu minimieren. Der Verlust wird berechnet, indem die Ausgabe des Modells und die tatsächlichen Labels verglichen werden.\n",
    "\n",
    "Nach jeder Epoche wird die Genauigkeit des Modells auf den Testdaten berechnet. Wenn die Genauigkeit über 90% liegt, wird der aktuelle Zustand des Modells gespeichert. Wenn die Genauigkeit nicht besser ist als die bisher beste Genauigkeit, wird der `early_stopping_counter` erhöht. Wenn der `early_stopping_counter` den Wert von `patience` erreicht, wird das Training gestoppt.\n",
    "\n",
    "## Ausgabe\n",
    "\n",
    "Das Skript gibt den Verlust und die Genauigkeit nach jeder Epoche aus. Wenn das Training aufgrund von Early Stopping gestoppt wird, wird eine entsprechende Nachricht ausgegeben. Am Ende des Trainings wird eine Nachricht ausgegeben, dass das Training abgeschlossen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "patience = 10 \n",
    "best_accuracy = 0.0  \n",
    "early_stopping_counter = 0  \n",
    "\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "      \n",
    "        inputs, labels = data\n",
    "\n",
    "   \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "   \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "   \n",
    "        running_loss += loss.item()\n",
    "\n",
    "  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if i % 10 == 9: \n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 100))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for val_data in test_dataloader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_outputs = model(val_images)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "\n",
    "\n",
    "    if accuracy > 0.9:  \n",
    "        torch.save(model.state_dict(), f'model/PyTorch_Trained_Models/model_epoch_{epoch+1}_accuracy_{accuracy:.2f}.pth')\n",
    "   \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        early_stopping_counter = 0\n",
    "        print(f\"Genauigkeit: {accuracy:.2f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "model_path_git = f'model/PyTorch_Trained_Models/'\n",
    "model_test_path = f'test/model_to_be_tested'\n",
    "\n",
    "torch.save(model.state_dict(), f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth')\n",
    "torch.save(model.state_dict(), f'{model_test_path}' + '.pth')\n",
    "model_path_test = \"f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 ML-Model Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 PyTorch Modell Inferenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Modell Inferenz\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch.\n",
    "\n",
    "##### Modellpfad und Gerätekonfiguration\n",
    "\n",
    "```python\n",
    "model_path = f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "\n",
    "Zuerst wird der Pfad zum vortrainierten Modell erstellt, indem der Basispfad, der Name des Modells, die Batch-Größe und die Anzahl der Epochen kombiniert werden. Dann wird das Gerät auf \"cuda\" gesetzt, wenn eine GPU verfügbar ist, sonst auf \"cpu\".\n",
    "\n",
    "##### Modellinitialisierung und Gewichtsladung\n",
    "\n",
    "```python\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "```\n",
    "\n",
    "Ein neues Modell wird erstellt (in diesem Fall ein einfaches CNN). Das Modell wird dann mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind.\n",
    "\n",
    "##### Inferenz auf dem Testdatensatz\n",
    "\n",
    "```python\n",
    "for inputs, _ in test_dataloader:\n",
    "    inputs = inputs.to(device) \n",
    "    output = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)\n",
    "```\n",
    "\n",
    "Für jede Eingabe im Testdatensatz werden die Eingaben auf das Gerät verschoben (GPU oder CPU). Das Modell macht dann eine Vorhersage auf den Eingaben. Die Ausgabe des Modells wird in Wahrscheinlichkeiten umgewandelt, indem die Softmax-Funktion angewendet wird. Die Klasse mit der höchsten Wahrscheinlichkeit wird als Vorhersage ausgewählt. Schließlich werden die Vorhersagen in eine Liste umgewandelt und ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Der Pfad zum Modell wird erstellt, indem der Basispfad, der Name des Modells, die Batch-Größe und die Anzahl der Epochen kombiniert werden.\n",
    "model_path = f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth'\n",
    "\n",
    "# Das Gerät wird auf \"cuda\" gesetzt, wenn eine GPU verfügbar ist, sonst auf \"cpu\".\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ein neues Modell wird erstellt (in diesem Fall ein einfaches CNN).\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Das Modell wird mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind.\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Ein DataLoader für den Testdatensatz wird erstellt (diese Zeile ist auskommentiert).\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Für jede Eingabe im Testdatensatz:\n",
    "for inputs, _ in test_dataloader:\n",
    "    # Die Eingaben werden auf das Gerät verschoben (GPU oder CPU).\n",
    "    inputs = inputs.to(device) \n",
    "    # Das Modell macht eine Vorhersage auf den Eingaben.\n",
    "    output = model(inputs)\n",
    "    # Die Ausgabe des Modells wird in Wahrscheinlichkeiten umgewandelt, indem die Softmax-Funktion angewendet wird.\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    # Die Klasse mit der höchsten Wahrscheinlichkeit wird als Vorhersage ausgewählt.\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    # Die Vorhersagen werden in eine Liste umgewandelt und ausgegeben.\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 PyTorch Modell Inferenz und Genauigkeitsberechnung\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch und berechnet die Genauigkeit der Vorhersagen.\n",
    "\n",
    "### Modellladen und Testdaten-Loader\n",
    "\n",
    "```python\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "```\n",
    "\n",
    "Zuerst wird ein neues Modell erstellt (in diesem Fall ein einfaches CNN) und mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind. Dann wird ein DataLoader für den Testdatensatz erstellt, mit einer Batch-Größe von 64 und ohne Shuffle.\n",
    "\n",
    "### Inferenz und Genauigkeitsberechnung\n",
    "\n",
    "```python\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Genauigkeit des Modells auf Testbilder: {}%'.format(100 * accuracy))\n",
    "```\n",
    "\n",
    "Zwei Zähler werden initialisiert: `correct` für die Anzahl der korrekten Vorhersagen und `total` für die Gesamtzahl der Vorhersagen. Für jede Eingabe und das zugehörige Label im Testdatensatz werden die Eingaben und Labels auf das Gerät verschoben (GPU oder CPU). Das Modell macht dann eine Vorhersage auf den Eingaben und die Klasse mit der höchsten Ausgabe wird als Vorhersage ausgewählt. Die `total` und `correct` Zähler werden entsprechend aktualisiert. Schließlich wird die Genauigkeit berechnet als das Verhältnis von `correct` zu `total` und ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model laden\n",
    "model = SimpleCNN()\n",
    "# model.load_state_dict(torch.load(f'model/model{batch_size}' + '-' + f'{epochs}' + '.pth'))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# Assume `test_dataset` is your ImageFolder dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model für die Predictions und Genauigkeitberechnung verwenden\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Genauigkeit berechnen\n",
    "accuracy = correct / total\n",
    "print('Genauigkeit des Modells auf Testbilder: {}%'.format(100 * accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 PyTorch Modell Inferenz und Metrikenberechnung\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch und berechnet verschiedene Metriken zur Beurteilung der Modellleistung.\n",
    "\n",
    "### Modell Evaluierung und Inferenz\n",
    "\n",
    "```python\n",
    "model.eval() \n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted)\n",
    "        true_labels.extend(labels)\n",
    "```\n",
    "\n",
    "Zuerst wird das Modell in den Evaluierungsmodus gesetzt. Dann werden zwei Listen initialisiert: `predictions` für die Vorhersagen des Modells und `true_labels` für die tatsächlichen Labels. Für jede Eingabe und das zugehörige Label im Testdatensatz macht das Modell eine Vorhersage und die Klasse mit der höchsten Ausgabe wird als Vorhersage ausgewählt. Die Vorhersagen und tatsächlichen Labels werden den entsprechenden Listen hinzugefügt.\n",
    "\n",
    "### Konvertierung in numpy-Arrays und Metrikenberechnung\n",
    "\n",
    "```python\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "```\n",
    "\n",
    "Die Listen `predictions` und `true_labels` werden in numpy-Arrays umgewandelt. Dann werden verschiedene Metriken berechnet: Genauigkeit, gewichtete Präzision, gewichteter Recall und gewichteter F1-Score. Diese Metriken werden ausgegeben.\n",
    "\n",
    "### Speichern der Metriken\n",
    "\n",
    "```python\n",
    "with open('model/metrics/metrics.txt', 'w') as outfile:\n",
    "    outfile.write(f'Modellmetriken: Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "```\n",
    "\n",
    "Die berechneten Metriken werden in einer Textdatei gespeichert.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setze das Modell in den Evaluierungsmodus\n",
    "model.eval() \n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted)\n",
    "        true_labels.extend(labels)\n",
    "\n",
    "\n",
    "# Konvertiere die Listen in numpy-Arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Berechne die Metriken\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "\n",
    "with open('model/metrics/metrics.txt', 'w') as outfile:\n",
    "    outfile.write(f'Modellmetriken: Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Flatten the outputs and convert to numpy array\n",
    "        predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "        \n",
    "# Flatten the arrays\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "print(predictions)\n",
    "print(labels_list)\n",
    "\n",
    "# Ensure both arrays have the same length\n",
    "min_length = min(len(predictions), len(labels_list))\n",
    "predictions = predictions[:min_length]\n",
    "labels_list = labels_list[:min_length]\n",
    "\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "\n",
    "# Plot true labels against predictions\n",
    "# plt.scatter(labels_list,predictions)\n",
    "plt.scatter(labels_list,predictions)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "\n",
    "plt.savefig(\"model/plots/plot_scatter.jpg\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot([labels_list.min(), labels_list.max()], [predictions.min(), predictions.max()], 'k--', lw=4)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "plt.savefig(\"model/plots/plot_plt.jpg\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "# Create a 2D histogram from the data\n",
    "heatmap_data, xedges, yedges = np.histogram2d(labels_list, predictions, bins=50)\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.imshow(heatmap_data, origin='lower', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Anzahl')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Heatmap of True Labels vs Predictions')\n",
    "plt.savefig(\"model/plots/heatmap.jpg\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 ML-Test mit Fairlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Daten für Fairlearn vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "y_pred = []\n",
    "sensitive_features = [\"men\",\"women\"]\n",
    "\n",
    "train_men = \"data/output/train/men\"\n",
    "train_women = \"data/output/train/women\"\n",
    "val_men = \"data/output/val/men\"\n",
    "val_women = \"data/output/val/women\"\n",
    "csv = \"data/source_csv/list_attr_celeba.csv\"\n",
    "folder = \"data/img_align_celeba\"\n",
    "train = \"data/output/train\"\n",
    "test = \"data/output/val\"\n",
    "merged_csv = \"data/merged_features.csv\"   \n",
    "\n",
    "# Transformation der Daten für das Training und Testen  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((178, 218)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)     \n",
    "# Lesen Sie die CSV-Datei\n",
    "df = pd.read_csv(merged_csv)\n",
    "\n",
    "# Extrahieren Sie die Werte der 'male' Spalte\n",
    "sensitive_features = df['Male'].tolist()\n",
    "sensitive_features = pd.Series(sensitive_features).replace({-1: 'Frau', 1: 'Mann'}).tolist()\n",
    "\n",
    "\n",
    "\n",
    "# model_path = \"model/PyTorch_Trained_Models/model64-1.pth\"\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "for inputs, labels in train_dataloader:\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_test.extend(labels.numpy())\n",
    "    y_pred.extend(preds.numpy())\n",
    "    # Fügen Sie hier Ihren Code hinzu, um die sensiblen Merkmale für jede Vorhersage zu extrahieren\n",
    "    # sensitive_features.extend(extracted_features)\n",
    "\n",
    "# Berechnen Sie Fairness-Metriken\n",
    "metrics = MetricFrame(accuracy_score, y_test, y_pred, sensitive_features=sensitive_features)\n",
    "\n",
    "# Drucken Sie die Fairness-Metriken aus\n",
    "print(metrics.by_group)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Erstellen Sie eine Liste der Gruppennamen und ihrer Genauigkeiten\n",
    "groups = metrics.by_group.index.tolist()\n",
    "accuracies = metrics.by_group.values.tolist()\n",
    "\n",
    "# Erstellen Sie ein Balkendiagramm\n",
    "plt.bar(groups, accuracies)\n",
    "\n",
    "# Fügen Sie Titel und Beschriftungen hinzu\n",
    "plt.title('Accuracy by group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Zeigen Sie das Diagramm an\n",
    "plt.show()\n",
    "plt.savefig(\"model/plots/plot_bar.jpg\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")\n",
    "\n",
    "sensitive_features = pd.Series(sensitive_features).replace({-1: 'Frau', 1: 'Mann'}).tolist()\n",
    "# Analyze metrics using MetricFrame\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"false positive rate\": false_positive_rate,\n",
    "    \"false negative rate\": false_negative_rate,\n",
    "    \"selection rate\": selection_rate,\n",
    "    \"count\": count,\n",
    "}\n",
    "metric_frame = MetricFrame(\n",
    "    metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_features\n",
    ")\n",
    "ax = metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Metriken anzeigen!\",\n",
    ")\n",
    "# Durchlaufen Sie jeden Subplot und passen Sie die y-Achsen-Ticks an\n",
    "for row in ax:\n",
    "    for subplot in row:\n",
    "        subplot.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "# Zeigen Sie die Plots an\n",
    "plt.show()\n",
    "plt.savefig(\"model/plots/metrics.jpg\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Customize plots with ylim\n",
    "metric_frame.by_group.plot(\n",
    "    kind=\"bar\",\n",
    "    ylim=[0, 2],\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics with assigned y-axis range\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize plots with colormap\n",
    "metric_frame.by_group.plot(\n",
    "    kind=\"bar\",\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    colormap=\"Accent\",\n",
    "    title=\"Show all metrics in Accent colormap\",\n",
    ")\n",
    "\n",
    "\n",
    "# Saving plots\n",
    "fig = metric_frame.by_group[[\"count\"]].plot(\n",
    "    kind=\"pie\",\n",
    "    subplots=True,\n",
    "    layout=[1, 1],\n",
    "    legend=True,\n",
    "    figsize=[12, 8],\n",
    "    labels=[\"Frau\",\"Mann\"],\n",
    "    autopct=\"%.2f\",\n",
    "    title=\"Metriken als Kuchen-Diagramm\",\n",
    ")\n",
    "\n",
    "if \"__file__\" in locals():\n",
    "    fig[0][0].figure.savefig(\"model/plots/metricsFairLearn.jpg\", dpi=100)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
