{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importieren der benötigten Bibliotheken für das ML-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.datasets import fetch_adult\n",
    "import torchvision.transforms as transforms\n",
    "from torchcam.methods import GradCAM, SmoothGradCAMpp, LayerCAM, XGradCAM, ScoreCAM, GradCAMpp\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ML-Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Festlegen der Epochen und der Batchsize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "with open('test/epochs/batch_size.txt', 'w') as f:\n",
    "    f.write(str(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Transformierung und Normalisierung der Daten zu einem Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation der Daten für das Training und Testen  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((178, 218)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Dateipfade für das Training und Testen festlegen\n",
    "train_dataset = datasets.ImageFolder(root='data/train-test-data/train',transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root= 'data/train-test-data/test',transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Überprüfen ob die Bilder richtig angezeigt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "img = train_features[0].permute(1, 2, 0)\n",
    "plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Erstellen eines CNN-Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das CNN-Modell besteht aus 2 Convolutional Layers, 2 Pooling Layers, 2 Max Pooling Layers, 3 Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Erste Convolutional Layer. Nimmt 3 Eingangskanäle (RGB), gibt 6 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=4, Schrittgröße=4\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        # Zweite Convolutional Layer. Nimmt 6 Eingangskanäle (von der vorherigen Schicht), gibt 16 Kanäle aus, mit einer Kernelgröße von 5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Max-Pooling-Layer mit einem quadratischen Fenster der Kernelgröße=2, Schrittgröße=2\n",
    "        self.pool = nn.MaxPool2d(2,2) \n",
    "        # Erste vollständig verbundene Schicht. Nimmt einen abgeflachten Vektor der Größe 33456 auf, gibt einen Vektor der Größe 120 aus\n",
    "        self.fc1 = nn.Linear(33456 , 120) \n",
    "        # Zweite vollständig verbundene Schicht. Nimmt einen Vektor der Größe 120 auf, gibt einen Vektor der Größe 84 aus\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # Dritte vollständig verbundene Schicht. Nimmt einen Vektor der Größe 84 auf, gibt einen Vektor der Größe 2 aus\n",
    "        self.fc3 = nn.Linear(84, 2) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Anwendung der ersten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # Anwendung der zweiten Conv-Schicht, dann ReLU-Aktivierungsfunktion, dann Max-Pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Abflachen des Tensorausgangs von den Conv-Schichten\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # Anwendung der ersten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Anwendung der zweiten vollständig verbundenen Schicht, dann ReLU-Aktivierungsfunktion\n",
    "        x = F.relu(self.fc2(x)) \n",
    "        # Anwendung der dritten vollständig verbundenen Schicht\n",
    "        x = self.fc3(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ML-Modell trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dokumentation für PyTorch Trainingsskript\n",
    "\n",
    "Dieses Skript trainiert ein Convolutional Neural Network (CNN) mit PyTorch.\n",
    "\n",
    "## Variablen\n",
    "\n",
    "- `model`: Eine Instanz des `SimpleCNN` Modells.\n",
    "- `criterion`: Die Verlustfunktion, die während des Trainings verwendet wird. In diesem Fall wird die Cross-Entropy-Loss-Funktion verwendet.\n",
    "- `optimizer`: Der Optimierer, der zur Aktualisierung der Modellparameter verwendet wird. Hier wird der Stochastic Gradient Descent (SGD) Optimierer verwendet.\n",
    "- `patience`: Die Anzahl der Epochen, die auf eine Verbesserung der Genauigkeit gewartet wird, bevor das Training gestoppt wird.\n",
    "- `best_accuracy`: Die beste Genauigkeit, die während des Trainings erreicht wurde. Initialisiert auf 0.\n",
    "- `early_stopping_counter`: Zählt die Anzahl der Epochen ohne Verbesserung der Genauigkeit.\n",
    "\n",
    "## Trainingsschleife\n",
    "\n",
    "Das Modell wird für eine bestimmte Anzahl von Epochen trainiert. In jeder Epoche wird das Modell mit den Trainingsdaten trainiert und dann mit den Testdaten validiert.\n",
    "\n",
    "Während des Trainings werden die Modellparameter aktualisiert, um den Verlust zu minimieren. Der Verlust wird berechnet, indem die Ausgabe des Modells und die tatsächlichen Labels verglichen werden.\n",
    "\n",
    "Nach jeder Epoche wird die Genauigkeit des Modells auf den Testdaten berechnet. Wenn die Genauigkeit über 90% liegt, wird der aktuelle Zustand des Modells gespeichert. Wenn die Genauigkeit nicht besser ist als die bisher beste Genauigkeit, wird der `early_stopping_counter` erhöht. Wenn der `early_stopping_counter` den Wert von `patience` erreicht, wird das Training gestoppt.\n",
    "\n",
    "## Ausgabe\n",
    "\n",
    "Das Skript gibt den Verlust und die Genauigkeit nach jeder Epoche aus. Wenn das Training aufgrund von Early Stopping gestoppt wird, wird eine entsprechende Nachricht ausgegeben. Am Ende des Trainings wird eine Nachricht ausgegeben, dass das Training abgeschlossen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "patience = 10 \n",
    "best_accuracy = 0.0  \n",
    "early_stopping_counter = 0  \n",
    "\n",
    "for epoch in range(epochs): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_dataloader), 0):\n",
    "      \n",
    "        inputs, labels = data\n",
    "\n",
    "   \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "   \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "   \n",
    "        running_loss += loss.item()\n",
    "\n",
    "  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if i % 10 == 9: \n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "              (epoch + 1, i + 1, running_loss / 100))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for val_data in test_dataloader:\n",
    "            val_images, val_labels = val_data\n",
    "            val_outputs = model(val_images)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "\n",
    "\n",
    "    if accuracy > 0.9:  \n",
    "        torch.save(model.state_dict(), f'model/PyTorch_Trained_Models/model_epoch_{epoch+1}_accuracy_{accuracy:.2f}.pth')\n",
    "   \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        early_stopping_counter = 0\n",
    "        print(f\"Genauigkeit: {accuracy:.2f}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter >= patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "model_path_git = f'model/PyTorch_Trained_Models/'\n",
    "model_test_path = f'test/model_to_be_tested'\n",
    "\n",
    "torch.save(model.state_dict(), f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth')\n",
    "torch.save(model.state_dict(), f'{model_test_path}' + '.pth')\n",
    "model_path_test = \"f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Modell trainieren auf Basis augeglichener Daten junger und alt gelabelter Personen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
