{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importieren der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_train as pt\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from pytorch_train import SimpleCNN\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, cuda\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.optim import Adam\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fairlearn.datasets import fetch_adult\n",
    "import torchvision.transforms as transforms\n",
    "from torchcam.methods import GradCAM, SmoothGradCAMpp, LayerCAM, XGradCAM, ScoreCAM, GradCAMpp\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ML-Model Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 PyTorch Modell Inferenz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Modell Inferenz\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch.\n",
    "\n",
    "##### Modellpfad und Gerätekonfiguration\n",
    "\n",
    "```python\n",
    "model_path = f'{model_path_git}model_git{batch_size}' + '-' + f'{epochs}' + '.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "```\n",
    "\n",
    "Zuerst wird der Pfad zum vortrainierten Modell erstellt, indem der Basispfad, der Name des Modells, die Batch-Größe und die Anzahl der Epochen kombiniert werden. Dann wird das Gerät auf \"cuda\" gesetzt, wenn eine GPU verfügbar ist, sonst auf \"cpu\".\n",
    "\n",
    "##### Modellinitialisierung und Gewichtsladung\n",
    "\n",
    "```python\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "```\n",
    "\n",
    "Ein neues Modell wird erstellt (in diesem Fall ein einfaches CNN). Das Modell wird dann mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind.\n",
    "\n",
    "##### Inferenz auf dem Testdatensatz\n",
    "\n",
    "```python\n",
    "for inputs, _ in test_dataloader:\n",
    "    inputs = inputs.to(device) \n",
    "    output = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)\n",
    "```\n",
    "\n",
    "Für jede Eingabe im Testdatensatz werden die Eingaben auf das Gerät verschoben (GPU oder CPU). Das Modell macht dann eine Vorhersage auf den Eingaben. Die Ausgabe des Modells wird in Wahrscheinlichkeiten umgewandelt, indem die Softmax-Funktion angewendet wird. Die Klasse mit der höchsten Wahrscheinlichkeit wird als Vorhersage ausgewählt. Schließlich werden die Vorhersagen in eine Liste umgewandelt und ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model und zu testendes Modell festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "def get_model_path(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pth\"):\n",
    "            return os.path.join(directory, filename)\n",
    "    return None\n",
    "\n",
    "model_path = get_model_path(\"test/model_to_be_tested\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation der Daten für das Training und Testen  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((178, 218)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testdataset/-dataloader festlegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "with open('test/epochs/batch_size.txt', 'r') as f:\n",
    "    batch_size = int(f.read())\n",
    "    \n",
    "test_dataset = datasets.ImageFolder(root= 'data/train-test-data/test',transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerät auswählen worauf das Modell trainiert werden soll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Gerät wird auf \"cuda\" gesetzt, wenn eine GPU verfügbar ist, sonst auf \"cpu\".\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zu testendes Modell laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Modell wird mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind.\n",
    "model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell in Evaluations-Modus versetzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell auf Grundlage des Testdataloaders testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Für jede Eingabe im Testdatensatz:\n",
    "for inputs, _ in test_dataloader:\n",
    "    # Die Eingaben werden auf das Gerät verschoben (GPU oder CPU).\n",
    "    inputs = inputs.to(device) \n",
    "    # Das Modell macht eine Vorhersage auf den Eingaben.\n",
    "    output = model(inputs)\n",
    "    # Die Ausgabe des Modells wird in Wahrscheinlichkeiten umgewandelt, indem die Softmax-Funktion angewendet wird.\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    # Die Klasse mit der höchsten Wahrscheinlichkeit wird als Vorhersage ausgewählt.\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    # Die Vorhersagen werden in eine Liste umgewandelt und ausgegeben.\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 PyTorch Modell Inferenz und Genauigkeitsberechnung\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch und berechnet die Genauigkeit der Vorhersagen.\n",
    "\n",
    "### Modellladen und Testdaten-Loader\n",
    "\n",
    "```python\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "```\n",
    "\n",
    "Zuerst wird ein neues Modell erstellt (in diesem Fall ein einfaches CNN) und mit den Gewichten geladen, die unter dem angegebenen Pfad gespeichert sind. Dann wird ein DataLoader für den Testdatensatz erstellt, mit einer Batch-Größe von 64 und ohne Shuffle.\n",
    "\n",
    "### Inferenz und Genauigkeitsberechnung\n",
    "\n",
    "```python\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print('Genauigkeit des Modells auf Testbilder: {}%'.format(100 * accuracy))\n",
    "```\n",
    "\n",
    "Zwei Zähler werden initialisiert: `correct` für die Anzahl der korrekten Vorhersagen und `total` für die Gesamtzahl der Vorhersagen. Für jede Eingabe und das zugehörige Label im Testdatensatz werden die Eingaben und Labels auf das Gerät verschoben (GPU oder CPU). Das Modell macht dann eine Vorhersage auf den Eingaben und die Klasse mit der höchsten Ausgabe wird als Vorhersage ausgewählt. Die `total` und `correct` Zähler werden entsprechend aktualisiert. Schließlich wird die Genauigkeit berechnet als das Verhältnis von `correct` zu `total` und ausgegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 PyTorch Modell Inferenz und Metrikenberechnung\n",
    "\n",
    "Dieser Codeblock führt Inferenz (Vorhersagen) auf einem Testdatensatz mit einem vortrainierten PyTorch Modell durch und berechnet verschiedene Metriken zur Beurteilung der Modellleistung.\n",
    "\n",
    "### Modell Evaluierung und Inferenz\n",
    "\n",
    "```python\n",
    "model.eval() \n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted)\n",
    "        true_labels.extend(labels)\n",
    "```\n",
    "\n",
    "Zuerst wird das Modell in den Evaluierungsmodus gesetzt. Dann werden zwei Listen initialisiert: `predictions` für die Vorhersagen des Modells und `true_labels` für die tatsächlichen Labels. Für jede Eingabe und das zugehörige Label im Testdatensatz macht das Modell eine Vorhersage und die Klasse mit der höchsten Ausgabe wird als Vorhersage ausgewählt. Die Vorhersagen und tatsächlichen Labels werden den entsprechenden Listen hinzugefügt.\n",
    "\n",
    "### Konvertierung in numpy-Arrays und Metrikenberechnung\n",
    "\n",
    "```python\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "```\n",
    "\n",
    "Die Listen `predictions` und `true_labels` werden in numpy-Arrays umgewandelt. Dann werden verschiedene Metriken berechnet: Genauigkeit, gewichtete Präzision, gewichteter Recall und gewichteter F1-Score. Diese Metriken werden ausgegeben.\n",
    "\n",
    "### Speichern der Metriken\n",
    "\n",
    "```python\n",
    "with open('model/metrics/metrics.txt', 'w') as outfile:\n",
    "    outfile.write(f'Modellmetriken: Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "```\n",
    "\n",
    "Die berechneten Metriken werden in einer Textdatei gespeichert.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "# Setze das Modell in den Evaluierungsmodus\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted)\n",
    "        true_labels.extend(labels)\n",
    "\n",
    "\n",
    "# Konvertiere die Listen in numpy-Arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Berechne die Metriken\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions, average='weighted')\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f'Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
    "\n",
    "with open('model/metrics/metrics.txt', 'w') as outfile:\n",
    "    outfile.write(f'Modellmetriken: Genauigkeit: {accuracy}, Präzision: {precision}, Recall: {recall}, F1-Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        outputs = model(data)\n",
    "        \n",
    "        # Flatten the outputs and convert to numpy array\n",
    "        predictions.extend(outputs.view(-1).cpu().numpy())\n",
    "        labels_list.extend(labels.cpu().numpy())\n",
    "        \n",
    "# Flatten the arrays\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "print(predictions)\n",
    "print(labels_list)\n",
    "\n",
    "# Ensure both arrays have the same length\n",
    "min_length = min(len(predictions), len(labels_list))\n",
    "predictions = predictions[:min_length]\n",
    "labels_list = labels_list[:min_length]\n",
    "\n",
    "predictions = np.array(predictions).ravel()\n",
    "labels_list = np.array(labels_list).ravel()\n",
    "\n",
    "# Plot true labels against predictions\n",
    "# plt.scatter(labels_list,predictions)\n",
    "plt.scatter(labels_list,predictions)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "\n",
    "plt.savefig(\"model/plots/plot_scatter.jpg\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot([labels_list.min(), labels_list.max()], [predictions.min(), predictions.max()], 'k--', lw=4)\n",
    "plt.grid(True)\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.xlabel('True Labels',color='blue')\n",
    "plt.ylabel('Predictions',color='red')\n",
    "plt.title('True Labels vs Predictions')\n",
    "plt.savefig(\"model/plots/plot_plt.jpg\",dpi=100)\n",
    "plt.show()\n",
    "\n",
    "# Create a 2D histogram from the data\n",
    "heatmap_data, xedges, yedges = np.histogram2d(labels_list, predictions, bins=50)\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.imshow(heatmap_data, origin='lower', cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(label='Anzahl')\n",
    "plt.xlabel('True Labels')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Heatmap of True Labels vs Predictions')\n",
    "plt.savefig(\"model/plots/heatmap.jpg\", dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 ML-Test mit Fairlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3.1 Daten für Fairlearn vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraktion der Bilder und Labels für Fairlearn -> Speicherung in einer CSV-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "train_men = r\"data/train-test-data/train/men\"\n",
    "train_women = r\"data/train-test-data/train/women\"\n",
    "def create_gender_labelled_csv(men_folder, women_folder, output_csv):\n",
    "    # Liste der Dateien in den Ordnern erstellen\n",
    "    men_files = os.listdir(men_folder)\n",
    "    women_files = os.listdir(women_folder)\n",
    "\n",
    "    # DataFrame für Männer und Frauen erstellen\n",
    "    men_df = pd.DataFrame({\n",
    "        'filename': men_files,\n",
    "        'Male': [1]*len(men_files)  # 1 für Männer\n",
    "    })\n",
    "\n",
    "    women_df = pd.DataFrame({\n",
    "        'filename': women_files,\n",
    "        'Male': [-1]*len(women_files)  # -1 für Frauen\n",
    "    })\n",
    "\n",
    "    # Beide DataFrames zusammenfügen\n",
    "    combined_df = pd.concat([men_df, women_df])\n",
    "\n",
    "    # DataFrame als CSV speichern\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Funktion aufrufen\n",
    "create_gender_labelled_csv(train_men, train_women, \"gender_labelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "y_pred = []\n",
    "sensitive_features = [\"men\",\"women\"]\n",
    "\n",
    "train_men = \"data/train-test-data/train/men\"\n",
    "train_women = \"data/train-test-data/train/women\"\n",
    "val_men = \"data/train-test-data/test/men\"\n",
    "val_women = \"data/train-test-data/test/women\"\n",
    "csv = \"data/source_csv/list_attr_celeba.csv\"\n",
    "folder = \"data/img_align_celeba\"\n",
    "train = \"data/train-test-data/train\"\n",
    "test = \"data/train-test-data/test\"\n",
    "merged_csv = \"gender_labelled.csv\"   \n",
    "\n",
    "# Transformation der Daten für das Training und Testen  \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((178, 218)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.ImageFolder(train, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)     \n",
    "\n",
    "# Lesen Sie die CSV-Datei\n",
    "df = pd.read_csv(merged_csv)\n",
    "\n",
    "# Extrahieren Sie die Werte der 'male' Spalte\n",
    "sensitive_features = df['Male'].tolist()\n",
    "sensitive_features = pd.Series(sensitive_features).replace({-1: 'Frau', 1: 'Mann'}).tolist()\n",
    "\n",
    "\n",
    "for inputs, labels in train_dataloader:\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_test.extend(labels.numpy())\n",
    "    y_pred.extend(preds.numpy())\n",
    "\n",
    "    # sensitive_features.extend(extracted_features)\n",
    "\n",
    "# Berechnung der Fairness-Metriken\n",
    "metrics = MetricFrame(accuracy_score, y_test, y_pred, sensitive_features=sensitive_features)\n",
    "\n",
    "# Fairness-Metriken ausgeben\n",
    "print(metrics.by_group)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Erstellen Sie eine Liste der Gruppennamen und ihrer Genauigkeiten\n",
    "groups = metrics.by_group.index.tolist()\n",
    "accuracies = metrics.by_group.values.tolist()\n",
    "\n",
    "# Erstellen Sie ein Balkendiagramm\n",
    "plt.bar(groups, accuracies)\n",
    "\n",
    "# Fügen Sie Titel und Beschriftungen hinzu\n",
    "plt.title('Accuracy by group')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Zeigen Sie das Diagramm an\n",
    "plt.show()\n",
    "plt.savefig(\"test/metrics/plots/plot_bar.jpg\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")\n",
    "\n",
    "sensitive_features = pd.Series(sensitive_features).replace({-1: 'Frau', 1: 'Mann'}).tolist()\n",
    "# Analyze metrics using MetricFrame\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"false positive rate\": false_positive_rate,\n",
    "    \"false negative rate\": false_negative_rate,\n",
    "    \"selection rate\": selection_rate,\n",
    "    \"count\": count,\n",
    "}\n",
    "metric_frame = MetricFrame(\n",
    "    metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_features\n",
    ")\n",
    "ax = metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Metriken anzeigen!\",\n",
    ")\n",
    "# Durchlaufen Sie jeden Subplot und passen Sie die y-Achsen-Ticks an\n",
    "for row in ax:\n",
    "    for subplot in row:\n",
    "        subplot.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "\n",
    "# Zeigen Sie die Plots an\n",
    "plt.show()\n",
    "plt.savefig(\"test/metrics/plots/metrics.jpg\", dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Customize plots with ylim\n",
    "metric_frame.by_group.plot(\n",
    "    kind=\"bar\",\n",
    "    ylim=[0, 2],\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Show all metrics with assigned y-axis range\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize plots with colormap\n",
    "metric_frame.by_group.plot(\n",
    "    kind=\"bar\",\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    colormap=\"Accent\",\n",
    "    title=\"Show all metrics in Accent colormap\",\n",
    ")\n",
    "\n",
    "\n",
    "# Saving plots\n",
    "fig = metric_frame.by_group[[\"count\"]].plot(\n",
    "    kind=\"pie\",\n",
    "    subplots=True,\n",
    "    layout=[1, 1],\n",
    "    legend=True,\n",
    "    figsize=[12, 8],\n",
    "    labels=[\"Frau\",\"Mann\"],\n",
    "    autopct=\"%.2f\",\n",
    "    title=\"Metriken als Kuchen-Diagramm\",\n",
    ")\n",
    "\n",
    "if \"__file__\" in locals():\n",
    "    fig[0][0].figure.savefig(\"test/metricsFairlearn/metricsFairLearn.jpg\", dpi=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Testdataset erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "model = SimpleCNN()  # Instantiate the model\n",
    "\n",
    "\n",
    "# model_path = f'model/PyTorch_Trained_Models/model64-91acc-100.pth'\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))  # Load the state_dict\n",
    "test_dataset = datasets.ImageFolder(\"data/train-test-data/test\", transform=transform)\n",
    "# test_dataset = datasets.ImageFolder(r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\output\\val\", transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "for inputs, _ in test_dataloader:\n",
    "    inputs = inputs.to(device) \n",
    "    output = model(inputs)\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    predictions_list = predictions.cpu().numpy().tolist()\n",
    "    print(predictions_list)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Robustheit des ML-Models Testen auf Testbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def test_model_robustness(model, test_dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Do not calculate gradients to speed up computation\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    print(f'::warning::Accuracy: {accuracy}')\n",
    "    print(f'::warning::Precision: {precision}')\n",
    "    print(f'::warning::Recall: {recall}')\n",
    "    print(f'::warning::F1 Score: {f1}')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "test_model_robustness(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Testdaten verrauschen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add_noise` Funktion\n",
    "Die Funktion `add_noise` fügt einem gegebenen Bild Rauschen hinzu.\n",
    "\n",
    "#### Parameter\n",
    "\n",
    "- `images`: Die Bilder, zu denen Rauschen hinzugefügt werden soll.\n",
    "- `noise_factor`: Der Faktor, der bestimmt, wie viel Rauschen hinzugefügt wird. Standardmäßig ist dieser Wert 0.5.\n",
    "\n",
    "#### Rückgabewert\n",
    "\n",
    "Die Funktion gibt die verrauschten Bilder zurück.\n",
    "\n",
    "### `add_noise_and_test` Funktion\n",
    "\n",
    "Die Funktion `add_noise_and_test` fügt den Testbildern Rauschen hinzu und testet dann das Modell mit diesen verrauschten Bildern.\n",
    "\n",
    "#### Parameter\n",
    "\n",
    "- `model`: Das zu testende Modell.\n",
    "- `test_dataloader`: Ein DataLoader, der die Testdaten bereitstellt.\n",
    "- `device`: Das Gerät, auf dem das Modell ausgeführt wird (z.B. 'cpu' oder 'cuda').\n",
    "- `noise_factor`: Der Faktor, der bestimmt, wie viel Rauschen hinzugefügt wird. Standardmäßig ist dieser Wert 0.5.\n",
    "\n",
    "#### Funktionsweise\n",
    "\n",
    "Die Funktion fügt den Testbildern Rauschen hinzu und erstellt dann einen neuen DataLoader mit den verrauschten Bildern. Anschließend wird das Modell mit diesen verrauschten Bildern getestet.\n",
    "\n",
    "### Beispiel\n",
    "\n",
    "```python\n",
    "add_noise_and_test(model, test_dataloader, device)\n",
    "```\n",
    "\n",
    "In diesem Beispiel wird die Funktion `add_noise_and_test` aufgerufen, um Rauschen zu den Testbildern hinzuzufügen und dann das Modell `model` mit diesen verrauschten Bildern zu testen. Die Testdaten werden vom `test_dataloader` bereitgestellt und das Modell wird auf dem `device` ausgeführt. Der Rauschfaktor beträgt 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(images, noise_factor=0.5):\n",
    "    noise = torch.randn_like(images) * noise_factor\n",
    "    noisy_images = images + noise\n",
    "    noisy_images = torch.clamp(noisy_images, 0., 1.)\n",
    "    return noisy_images\n",
    "\n",
    "def add_noise_and_test(model, test_dataloader, device, noise_factor=0.5):\n",
    "    noisy_images = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs_noisy = add_noise(inputs, noise_factor)\n",
    "        noisy_images.append(inputs_noisy)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    # Stack images and labels separately\n",
    "    noisy_images = torch.cat(noisy_images)\n",
    "    labels_list = torch.cat(labels_list)\n",
    "\n",
    "    noisy_dataloader = torch.utils.data.DataLoader(list(zip(noisy_images, labels_list)), batch_size=test_dataloader.batch_size)\n",
    "\n",
    "    test_model_robustness(model, noisy_dataloader, device)\n",
    "\n",
    "# Verwendung der Funktion\n",
    "add_noise_and_test(model, test_dataloader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Model auf verrauschte Bilder testen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dokumentation für `test_noise_robustness` Funktion\n",
    "\n",
    "Die Funktion `test_noise_robustness` testet die Robustheit eines Modells gegenüber Bildrauschen. Sie nimmt ein Modell, einen DataLoader für Testdaten, ein Gerät und optionale Parameter für den Start-, End- und Schrittwert des Rauschfaktors an.\n",
    "\n",
    "### Parameter\n",
    "\n",
    "- `model`: Das zu testende Modell.\n",
    "- `test_dataloader`: Ein DataLoader, der die Testdaten bereitstellt.\n",
    "- `device`: Das Gerät, auf dem das Modell ausgeführt wird (z.B. 'cpu' oder 'cuda').\n",
    "- `start_noise`: Der Startwert für den Rauschfaktor. Standardmäßig ist dieser Wert 0.0.\n",
    "- `end_noise`: Der Endwert für den Rauschfaktor. Standardmäßig ist dieser Wert 1.0.\n",
    "- `step`: Der Schrittwert, um den der Rauschfaktor bei jedem Durchlauf erhöht wird. Standardmäßig ist dieser Wert 0.1.\n",
    "\n",
    "### Funktionsweise\n",
    "\n",
    "Die Funktion fügt den Testbildern schrittweise Rauschen hinzu, beginnend mit dem `start_noise`-Wert und endend mit dem `end_noise`-Wert. Bei jedem Schritt wird das Modell mit den verrauschten Bildern getestet und die Genauigkeit, Precision, Recall und der F1-Score werden berechnet und neben einem Beispielbild angezeigt.\n",
    "\n",
    "Wenn die Genauigkeit des Modells unter 70% fällt, wird der Test gestoppt.\n",
    "\n",
    "### Beispiel\n",
    "\n",
    "```python\n",
    "test_noise_robustness(model, test_dataloader, device)\n",
    "```\n",
    "\n",
    "In diesem Beispiel wird die Funktion `test_noise_robustness` aufgerufen, um die Robustheit des Modells `model` gegenüber Bildrauschen zu testen. Die Testdaten werden vom `test_dataloader` bereitgestellt und das Modell wird auf dem `device` ausgeführt. Der Rauschfaktor startet bei 0.0 und endet bei 1.0, wobei er bei jedem Durchlauf um 0.1 erhöht wird.\n",
    "\n",
    "\n",
    "\n",
    "Die Funktion `test_noise_robustness` testet die Robustheit eines Modells gegenüber Bildrauschen. Sie nimmt ein Modell, einen DataLoader für Testdaten, ein Gerät und optionale Parameter für den Start-, End- und Schrittwert des Rauschfaktors an.\n",
    "\n",
    "### Parameter\n",
    "\n",
    "- `model`: Das zu testende Modell.\n",
    "- `test_dataloader`: Ein DataLoader, der die Testdaten bereitstellt.\n",
    "- `device`: Das Gerät, auf dem das Modell ausgeführt wird (z.B. 'cpu' oder 'cuda').\n",
    "- `start_noise`: Der Startwert für den Rauschfaktor. Standardmäßig ist dieser Wert 0.0.\n",
    "- `end_noise`: Der Endwert für den Rauschfaktor. Standardmäßig ist dieser Wert 1.0.\n",
    "- `step`: Der Schrittwert, um den der Rauschfaktor bei jedem Durchlauf erhöht wird. Standardmäßig ist dieser Wert 0.1.\n",
    "\n",
    "### Funktionsweise\n",
    "\n",
    "Die Funktion fügt den Testbildern schrittweise Rauschen hinzu, beginnend mit dem `start_noise`-Wert und endend mit dem `end_noise`-Wert. Bei jedem Schritt wird das Modell mit den verrauschten Bildern getestet und die Genauigkeit, Precision, Recall und der F1-Score werden berechnet und neben einem Beispielbild angezeigt.\n",
    "\n",
    "Wenn die Genauigkeit des Modells unter 70% fällt, wird der Test gestoppt.\n",
    "\n",
    "### Beispiel\n",
    "\n",
    "```python\n",
    "test_noise_robustness(model, test_dataloader, device)\n",
    "```\n",
    "\n",
    "In diesem Beispiel wird die Funktion `test_noise_robustness` aufgerufen, um die Robustheit des Modells `model` gegenüber Bildrauschen zu testen. Die Testdaten werden vom `test_dataloader` bereitgestellt und das Modell wird auf dem `device` ausgeführt. Der Rauschfaktor startet bei 0.0 und endet bei 1.0, wobei er bei jedem Durchlauf um 0.1 erhöht wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_noise_robustness(model, test_dataloader, device, start_noise=0.0, end_noise=1.0, step=0.1):\n",
    "    noise_factor = start_noise\n",
    "    i = 0\n",
    "    while noise_factor <= end_noise:\n",
    "        noisy_images = []\n",
    "        labels_list = []\n",
    "\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs_noisy = add_noise(inputs, noise_factor)\n",
    "            noisy_images.append(inputs_noisy)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "        noisy_images = torch.cat(noisy_images)\n",
    "        labels_list = torch.cat(labels_list)\n",
    "\n",
    "        noisy_dataloader = torch.utils.data.DataLoader(list(zip(noisy_images, labels_list)), batch_size=test_dataloader.batch_size)\n",
    "\n",
    "        print(f'::warning::Test mit noise factor: {noise_factor}')\n",
    "        accuracy, precision,recall, f1 = test_model_robustness(model, noisy_dataloader, device)\n",
    "        \n",
    "\n",
    "        # Show a sample noisy image\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(f'Verauschtes Bild mit noise factor: {noise_factor}.', fontsize=10)\n",
    "        plt.imshow(noisy_images[0].permute(1, 2, 0))\n",
    "        plt.text(1.2, 0.6, f'Genauigkeit: {accuracy}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.5, f'Precision: {precision}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.4, f'Recall: {recall}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.3, f'F1 Score: {f1}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.savefig(f\"test/test-plots-rauschen/{i}.png\")\n",
    "        print(f\"test/test-plots-verzerrung/{i}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        if accuracy < 0.7:\n",
    "            print(f'::warning::Genauigkeit unter 70% mit noise factor: {noise_factor}. Test wird gestoppt.')\n",
    "            break\n",
    "        i += 1\n",
    "        noise_factor += step\n",
    "\n",
    "# Verwendung der Funktion\n",
    "test_noise_robustness(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Testdaten mit Verzerrungen erstellen \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "def add_distortion(image, distortion_factor=0.5):\n",
    "    # Create the distortion matrix\n",
    "    startpoints = torch.tensor([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\n",
    "    endpoints = startpoints + torch.tensor([[0.0, distortion_factor], [0.0, -distortion_factor], [0.0, 0.0], [0.0, 0.0]])\n",
    "\n",
    "    # Apply the distortion to the image\n",
    "    distorted_image = TF.perspective(image, startpoints, endpoints)\n",
    "\n",
    "    return distorted_image\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distortion_robustness(model, test_dataloader, device, start_distortion=0.0, end_distortion=1.0, step=0.0001):\n",
    "    distortion_factor = start_distortion\n",
    "    i = 0\n",
    "    while distortion_factor <= end_distortion:\n",
    "        distorted_images = []\n",
    "        labels_list = []\n",
    "\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs_distorted = add_distortion(inputs, distortion_factor)\n",
    "            distorted_images.append(inputs_distorted)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "        distorted_images = torch.cat(distorted_images)\n",
    "        labels_list = torch.cat(labels_list)\n",
    "\n",
    "        distorted_dataloader = torch.utils.data.DataLoader(list(zip(distorted_images, labels_list)), batch_size=test_dataloader.batch_size)\n",
    "\n",
    "        print(f'Test mit distortion factor: {distortion_factor}')\n",
    "        accuracy, precision, recall, f1 = test_model_robustness(model, distorted_dataloader, device)\n",
    "        \n",
    "        # Show a sample distorted image\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(f'Verzerrtes Bild mit distortion factor: {distortion_factor}.', fontsize=10)\n",
    "        plt.imshow(distorted_images[0].permute(1, 2, 0))\n",
    "        plt.text(1.2, 0.6, f'Genauigkeit: {accuracy}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.5, f'Precision: {precision}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.4, f'Recall: {recall}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.text(1.2, 0.3, f'F1 Score: {f1}', horizontalalignment='left', verticalalignment='center', transform=plt.gca().transAxes)\n",
    "        plt.savefig(f\"test/test-plots-verzerrung/{i}.png\")\n",
    "        print(f\"test/test-plots-verzerrung/{i}.png\")\n",
    "        plt.show()\n",
    "\n",
    "        if accuracy < 0.7:\n",
    "            print(f'::warning::Genauigkeit unter 70% mit distortion factor: {distortion_factor}. Test wird gestoppt.')\n",
    "            break\n",
    "        i += 1\n",
    "        distortion_factor += step\n",
    "\n",
    "test_distortion_robustness(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Modell mit 90° Drehung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from pytorch_train import SimpleCNN\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_to_be_tested_path = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\PyTorch_Trained_Models\\model_epoch_18_accuracy_0.93.pth\"\n",
    "# model = SimpleCNN()  # Instantiate the model\n",
    "# def test_rotated_images(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loader:\n",
    "#             images, labels = data\n",
    "#             # Rotate the images by 90 degrees\n",
    "#             rotated_images = [np.array(Image.fromarray(img.numpy(), 'RGB').rotate(90)) for img in images]\n",
    "#             # Resize the images to be at least 5x5\n",
    "#             # Resize the images to be at least 32x32\n",
    "#             rotated_images_resized = [Image.fromarray(img).resize((max(32, img.shape[1]), max(32, img.shape[0]))) for img in rotated_images]\n",
    "#             images = torch.Tensor([np.array(img) for img in rotated_images_resized])\n",
    "#             images = images.permute(0, 3, 1, 2)\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print('::warning::Accuracy of the model on rotated test images: {}%'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(model_to_be_tested_path, map_location=device))  # Load the state_dict\n",
    "# # test_dataset = datasets.ImageFolder(\"data/output/val\", transform=transform)\n",
    "    \n",
    "# test_dataset = datasets.ImageFolder(\"C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/data/output/val\", transform=transform)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# test_rotated_images(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# def rotate_and_save_image(image_path = []):\n",
    "#     i = 0\n",
    "#     for image in image_path:\n",
    "#         if i == 10: \n",
    "#             break\n",
    "#         # Open the image file\n",
    "#         img = Image.open(image)\n",
    "#         # rand = np.random.randint(0, 360)\n",
    "#         # Rotate the image\n",
    "#         # rotated_img = img.rotate(rand)\n",
    "#         # Create the output folder if it doesn't exist\n",
    "#         # rotated_img.show()\n",
    "#         # if not os.path.exists(output_folder):\n",
    "#         #     os.makedirs(output_folder)\n",
    "#         # Save the rotated image to the output folder\n",
    "#         # output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "#         # rotated_img.save(output_path)\n",
    "#         # i += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from PIL import Image\n",
    "\n",
    "# def get_random_images(image_folder, num_images=10):\n",
    "#     # Get a list of all the image files in the folder\n",
    "#     image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "#     # Randomly select num_images files\n",
    "#     selected_files = random.sample(image_files, num_images)\n",
    "#     # Open the images and store them in a list\n",
    "#     images = [Image.open(img_path) for img_path in selected_files]\n",
    "#     return images\n",
    "\n",
    "# random_images_men = get_random_images(r\"data\\output\\val\\men\",10)\n",
    "# random_images_women = get_random_images(r\"data\\output\\val\\women\",10)\n",
    "# i = 0\n",
    "# for image in random_images_men:\n",
    "#     if i == 10: \n",
    "#         break\n",
    "#     # Open the image file\n",
    "#     # img = Image.open(image)\n",
    "#     rand = np.random.randint(0, 360)\n",
    "#     # Rotate the image\n",
    "#     rotated_img = image.rotate(rand)\n",
    "#     # Create the output folder if it doesn't exist\n",
    "#     rotated_img.show()\n",
    "#     # if not os.path.exists(output_folder):\n",
    "#     #     os.makedirs(output_folder)\n",
    "#     # Save the rotated image to the output folder\n",
    "#     # output_path = os.path.join(output_folder, os.path.basename(image_path))\n",
    "#     # rotated_img.save(output_path)\n",
    "#     i += 1\n",
    "\n",
    "# i=0\n",
    "# for image in random_images_women:\n",
    "#     if i == 10: \n",
    "#         break\n",
    "#     rand = np.random.randint(0, 360)\n",
    "#     rotated_img = image.rotate(rand)\n",
    "#     rotated_img.show()\n",
    "#     model.predict(rotated_img)\n",
    "#     i += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# # from torchvision import transforms\n",
    "\n",
    "# # Define the transformation\n",
    "# # transform = transforms.Compose([\n",
    "# #     transforms.ToTensor(),  # Convert the image to a tensor\n",
    "# #     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image\n",
    "# # ])\n",
    "\n",
    "# # Initialize a counter for the correct predictions\n",
    "# # correct = 0\n",
    "\n",
    "# # i=0\n",
    "# # for image, true_label in zip(random_images_women, true_labels):\n",
    "# #     if i == 10: \n",
    "# #         break\n",
    "# #     rand = np.random.randint(0, 360)\n",
    "# #     rotated_img = image.rotate(rand)\n",
    "    \n",
    "# #     Display the image\n",
    "# #     plt.imshow(rotated_img)\n",
    "# #     plt.show()\n",
    "    \n",
    "# #     Convert the image to a tensor and normalize it\n",
    "# #     input_img = transform(rotated_img).unsqueeze(0)\n",
    "# #     Move the input to the same device as the model\n",
    "# #     input_img = input_img.to(device)\n",
    "# #     Make a prediction\n",
    "# #     output = model(input_img)\n",
    "# #     _, predicted = torch.max(output.data, 1)\n",
    "# #     print(predicted)\n",
    "    \n",
    "# #     Check if the prediction is correct and increment the counter if it is\n",
    "# #     correct += (predicted == true_label).sum().item()\n",
    "# #     i += 1\n",
    "\n",
    "# # Calculate the accuracy\n",
    "# # accuracy = correct / i\n",
    "# # print('Accuracy: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
