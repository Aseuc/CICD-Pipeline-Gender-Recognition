{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importieren der benötigten Bibliotheken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tqdm\n",
    "import glob\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, binom_test, kstest, uniform\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Datenpreparation für das ML-Modell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Extrahieren der Bildpfade aus dem Ordner img_align_celeba \n",
    "##### Dies wird gemacht um die Pfade aus der Source-CSV: list_attr_celeba.csv in der Spalte image_id mit den richtigen Pfaden zu ersetzen. Somit sind die Pfade den Bildern richtig zugeordnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/source_csv/list_attr_celeba.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m required_directories \u001b[38;5;241m=\u001b[39m [source_train_path, women_image_source_path_test,men_image_source_path_test,men_image_source_path_train,women_image_source_path_train]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Erstellen der source.csv um automatisch die benötigten Spalten für die Visualisierung der Daten herauszuziehen.\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(source_csv)\n\u001b[0;32m     15\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/column_source_csv/source.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Hauptpfad zu den Bildern\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\busse\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\busse\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\busse\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\busse\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\busse\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/source_csv/list_attr_celeba.csv'"
     ]
    }
   ],
   "source": [
    "source_csv = \"data/source_csv/list_attr_celeba.csv\"\n",
    "csv_path=\"data/source_csv/list_attr_celeba.csv\"\n",
    "source_train_path = \"data/output/train\"\n",
    "men_image_source_path_train = \"data/output/train/men\"\n",
    "women_image_source_path_train = \"data/output/train/women\"\n",
    "men_image_source_path_test = \"data/output/val/men\"\n",
    "women_image_source_path_test = \"data/output/val/women\"\n",
    "merged_csv_test = \"model/csv_sheets/merged_df_test.csv\"\n",
    "merged_csv_train = \"model/csv_sheets/merged_df_train.csv\"\n",
    "required_directories = [source_train_path, women_image_source_path_test,men_image_source_path_test,men_image_source_path_train,women_image_source_path_train]\n",
    "\n",
    "\n",
    "# Erstellen der source.csv um automatisch die benötigten Spalten für die Visualisierung der Daten herauszuziehen.\n",
    "df = pd.read_csv(source_csv)\n",
    "df.to_csv(\"data/column_source_csv/source.csv\", index=False)\n",
    "\n",
    "\n",
    "# Hauptpfad zu den Bildern\n",
    "base_path = \"data/img_align_celeba\"\n",
    "\n",
    "# Extrahiert aus dem Source Pfad die Bildpfade\n",
    "def get_image_paths(source_path):\n",
    "    image_formats = ['*.jpg', '*.png', '*.gif', '*.jpeg']\n",
    "    image_paths = []\n",
    "    for format in image_formats:\n",
    "        image_paths.extend(glob.glob(os.path.join(source_path, format)))\n",
    "    return image_paths\n",
    "\n",
    "# Testet ob die Bilder in der CSV-Datei die richtigen Dateiendungen haben\n",
    "def test_image_extensions_in_csv(csv_path, column_name_of_image_paths=\"image_id\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Überprüfe, ob alle Werte in der Spalte 'image_id' auf Bilddateien verweisen\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    df['valid_extension'] = df[column_name_of_image_paths].apply(lambda x: os.path.splitext(x)[1].lower() in valid_extensions)\n",
    "\n",
    "    # Drucke die Zeilennummern mit ungültiger Dateierweiterung, wenn es welche gibt\n",
    "    invalid_rows = df[~df['valid_extension']].index\n",
    "    if len(invalid_rows) > 0:\n",
    "        print(f'Ungültige Dateierweiterungen gefunden in den Zeilen: {invalid_rows.tolist()}')\n",
    "\n",
    "    assert all(df['valid_extension']), f'Nicht alle Werte in der Spalte {column_name_of_image_paths} verweisen auf Bilddateien./n {invalid_rows} /n Überprüfe die Dateierweiterungen.'\n",
    "\n",
    "# Extrahieren der Bildpfade auf img_align_celeba\n",
    "image_paths_array = get_image_paths(base_path)\n",
    "\n",
    "# Erstellen eines Dataframes mit der Source CSV \n",
    "df = pd.read_csv(\"data/source_csv/list_attr_celeba.csv\")\n",
    "df['image_id'] = df['image_id'].str.replace(\"C:/Users/busse/Bachelorarbeit/CICD-Pipeline-Gender-Recognition/\", \"\")\n",
    "df.to_csv(\"data/source_csv/list_attr_celeba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Testen ob die Bildpfade in der CSV-Datei die richtige Dateiendung haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/source_csv/list_attr_celeba.csv\"\n",
    "test_image_extensions_in_csv(csv_path=csv_path, column_name_of_image_paths=\"image_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Überprüfen ob die Source_CSV im Dateiformat CSV ist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csv_extension(csv_path):\n",
    "    _, ext = os.path.splitext(csv_path)\n",
    "    assert ext.lower() == '.csv', f'Die Datei {csv_path} hat keine .csv Erweiterung'\n",
    "    \n",
    "check_csv_extension(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Überprüfen ob die benötigten Ordner vorhanden sind zum trainieren, testen, speichern der ML-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_directories_data_exists(directories):\n",
    "    for directory in directories:\n",
    "        assert os.path.isdir(directory), f'Das Verzeichnis {directory} existiert nicht'\n",
    "\n",
    "check_required_directories_data_exists(required_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Datenqualität testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Überprüfen ob Bilddateien fehlen, Duplicate vorhanden sind, Überprüfen ob die Bildpfade gültig sind in der CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quality_of_csv(csv_path,column_name_of_image_paths=\"image_id\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Überprüfe auf fehlende Werte\n",
    "    assert df[column_name_of_image_paths].isnull().sum() == 0, f'Es gibt fehlende Werte in der Spalte {column_name_of_image_paths}'\n",
    "\n",
    "    # Überprüfe auf Duplikate\n",
    "    assert df.duplicated().sum() == 0, \"Es gibt Duplikate in der Daten\"\n",
    "    \n",
    "    # Überprüfe, ob alle Werte in der Spalte 'image_id' gültige Bildpfade sind\n",
    "    assert all(df[column_name_of_image_paths].apply(os.path.isfile)), f'Nicht alle Werte in der Spalte {column_name_of_image_paths} sind gültige Bildpfade./n {df[column_name_of_image_paths].sample(10)} /n Überprüfe, ob der Pfad vorhanden ist.' \n",
    "\n",
    "test_quality_of_csv(source_csv, column_name_of_image_paths=df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Überprüfen ob es in allen Spalten Werte gibt die null bzw. leer sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    missing_values = df.isnull().any()\n",
    "    \n",
    "    return missing_values\n",
    "\n",
    "check_missing_values(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Überprüfen ob es Anomalien, Ausreißer gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_outliers_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            z_scores = np.abs((df[column_name] - df[column_name].mean()) / df[column_name].std())\n",
    "            if any(z_scores > 3):\n",
    "                print(f\"::warning::Es gibt Ausreißer in der Spalte '{column_name}'\")\n",
    "\n",
    "test_outliers_all_columns(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Überprüfen ob die Daten ausgeglichen sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    imbalance_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            if abs(counts.get(-1, 0) - counts.get(1, 0)) >= 0.1 * len(df):\n",
    "                imbalance_report.append(f\"Die Spalte '{column_name}' ist unausgeglichen. Anzahl von -1: {counts.get(-1, 0)}, Anzahl von 1: {counts.get(1, 0)}\")\n",
    "\n",
    "    if imbalance_report:\n",
    "        print(\"Es gibt unausgeglichene Spalten:/n\" + \"/n\".join(imbalance_report))\n",
    "\n",
    "def is_numeric(column):\n",
    "    try:\n",
    "        pd.to_numeric(column)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('data/column_source_csv/source.csv')\n",
    "\n",
    "# Filter the columns to only those with numeric data\n",
    "numeric_columns = [col for col in df.columns if is_numeric(df[col])]\n",
    "\n",
    "df = df[numeric_columns]\n",
    "df.to_csv(\"data/column_source_csv/source.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "def plot_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            counts.plot(kind='bar', title=f\"Verteilung der Werte in der Spalte '{column_name}'\")\n",
    "            plt.savefig(f\"data/plot_data/{column_name}.png\")\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "test_balance_all_columns(source_csv)\n",
    "plot_balance_all_columns(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Datensatz auf Ausreißer überprüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_all_outliers(df):\n",
    "    outliers_percentage = {}\n",
    "    \n",
    "    # Gehe durch jede Spalte im DataFrame\n",
    "    for column_name in df.columns:\n",
    "        # Überspringe nicht-numerische Spalten\n",
    "        if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "            # Berechne den IQR-Score\n",
    "            Q1 = df[column_name].quantile(0.25)\n",
    "            Q3 = df[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Definiere die Grenzen für Ausreißer\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Finde die Ausreißer\n",
    "            outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "            \n",
    "            # Berechne den Prozentsatz der Ausreißer\n",
    "            outliers_percentage[column_name] = len(outliers) / len(df) * 100\n",
    "    \n",
    "    return outliers_percentage\n",
    "\n",
    "\n",
    "def detect_outliers(df, column_name):\n",
    "    # Berechne den IQR-Score\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Definiere die Grenzen für Ausreißer\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Finde die Ausreißer\n",
    "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "\n",
    "    return outliers\n",
    "\n",
    "\n",
    "df = pd.read_csv(source_csv)\n",
    "detect_all_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Unausgeglichenheit der Daten von ein Paar Datensätzen auflösen um das Verhalten auf das ML-Modell zu beobachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Anpassen der Unausgeglichenheit zwischen Frauen und Mann Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gender_histogram(df):\n",
    "    # Zähle die Anzahl von Frauen und Männern\n",
    "    counts = df['Male'].value_counts()\n",
    "\n",
    "    # Plotte die Daten\n",
    "    plt.bar(['Female', 'Male'], [counts[-1], counts[1]], color=['#ff69b4', '#1f77b4'])\n",
    "\n",
    "    # Schreibe Text auf die Balken\n",
    "    for i, v in enumerate([counts[-1], counts[1]]):\n",
    "        plt.text(i, v, str(v), fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel('Gender')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def balance_column(csv_path, column_name):\n",
    "    # Lade die CSV-Datei in einen DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Zähle die Anzahl von -1 und 1\n",
    "    counts = df[column_name].value_counts()\n",
    "\n",
    "    # Finde den kleineren Wert\n",
    "    min_count = min(counts.get(-1, 0), counts.get(1, 0))\n",
    "\n",
    "    # Erstelle einen neuen DataFrame mit einer ausgeglichenen Anzahl von -1 und 1\n",
    "    df_balanced = pd.concat([\n",
    "        df[df[column_name] == -1].sample(min_count),\n",
    "        df[df[column_name] == 1].sample(min_count)\n",
    "    ], axis=0)\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "\n",
    "# Call the function with your csv file\n",
    "balanced_df = balance_column(source_csv, \"Male\")\n",
    "balanced_df.to_csv(\"data/balanced_source_csv/balanced_gender.csv\", index=False)\n",
    "\n",
    "balanced_csv_path =\"data/balanced_source_csv/balanced_gender.csv\"\n",
    "plot_gender_histogram(balanced_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Unausgeglichenheit zwischen Jungen und Alten Personendatensätzen ausgleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_young_histogram(df):\n",
    "    # Zähle die Anzahl von Frauen und Männern\n",
    "    counts = df[\"Young\"].value_counts()\n",
    "\n",
    "    # Plotte die Daten\n",
    "    plt.bar(['not Young', 'Young'], [counts[-1], counts[1]], color=['#ff69b4', '#1f77b4'])\n",
    "\n",
    "    # Schreibe Text auf die Balken\n",
    "    for i, v in enumerate([counts[-1], counts[1]]):\n",
    "        plt.text(i, v, str(v), fontsize=12, ha='center', va='bottom')\n",
    "    plt.title('Young oder nicht Young ohne Balanced Gender Data')\n",
    "    plt.xlabel('Young or not Young')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "young_balanced_csv = \"data/balanced_source_csv/balanced_young.csv\"\n",
    "df_young_balanced = balance_column(source_csv, \"Young\")\n",
    "df_young_balanced.to_csv(\"data/balanced_source_csv/balanced_young.csv\", index=False)\n",
    "df_young_balanced = pd.read_csv(young_balanced_csv)\n",
    "\n",
    "plot_young_histogram(df_young_balanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Datenverteilung Testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Daten auf Normalverteilung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "from scipy.stats import kstest, uniform\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def test_normal_distribution(data, column_name):\n",
    "    # Führe den Shapiro-Wilk-Test durch\n",
    "    stat, p = shapiro(data)\n",
    "\n",
    "    # Überprüfe das Ergebnis\n",
    "    if p > 0.05:\n",
    "        result = f'::warning::Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Normalverteilung.'\n",
    "    else:\n",
    "        result = f'::warning::Die Daten in der Spalte {column_name} folgen wahrscheinlich nicht einer Normalverteilung.'\n",
    "\n",
    "    with open(\"data/reports_data/norm_distribution.txt\", \"w\") as f:\n",
    "        f.write(result + \"\\n\")\n",
    "\n",
    "# Call the function with your data\n",
    "for column_name in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "        test_normal_distribution(df[column_name], column_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Daten auf Uniformverteilung/Gleichverteilung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_uniform_distribution(data, column_name):\n",
    "    # Generiere theoretische Werte für die Uniformverteilung\n",
    "    theoretical_values = uniform.rvs(size=len(data))\n",
    "\n",
    "    # Führe den KS-Test durch\n",
    "    stat, p = kstest(data, theoretical_values)\n",
    "\n",
    "    # Überprüfe das Ergebnis\n",
    "    if p > 0.05:\n",
    "        result = f'::warning::Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Uniformverteilung.'\n",
    "    else:\n",
    "        result = f'::warning::Die Daten in der Spalte {column_name} wahrscheinlich nicht einer Uniformverteilung.'\n",
    "\n",
    "    with open(\"data/reports_data/uniform_distribution.txt\", \"w\") as f:\n",
    "        f.write(result)\n",
    "\n",
    "# Call the function with your data\n",
    "for column_name in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "        test_uniform_distribution(df[column_name], column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Daten auf Binomialverteilung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Daten in der Spalte 5_o_Clock_Shadow folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Arched_Eyebrows folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Attractive folgen wahrscheinlich einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Bags_Under_Eyes folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Bald folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Bangs folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Big_Lips folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Big_Nose folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Black_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Blond_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Blurry folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Brown_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Bushy_Eyebrows folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Chubby folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Double_Chin folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Eyeglasses folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Goatee folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Gray_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Heavy_Makeup folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte High_Cheekbones folgen wahrscheinlich einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Male folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Mouth_Slightly_Open folgen wahrscheinlich einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Mustache folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Narrow_Eyes folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte No_Beard folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Oval_Face folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Pale_Skin folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Pointy_Nose folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Receding_Hairline folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Rosy_Cheeks folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Sideburns folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Smiling folgen wahrscheinlich einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Straight_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wavy_Hair folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wearing_Earrings folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wearing_Hat folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wearing_Lipstick folgen wahrscheinlich einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wearing_Necklace folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Wearing_Necktie folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n",
      "Die Daten in der Spalte Young folgen wahrscheinlich nicht einer Bernoulli-Verteilung.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_bernoulli_distribution(data, column_name, p):\n",
    "    data = data.replace(-1, 0) \n",
    "    value_counts = data.value_counts() \n",
    "    observed_values = [value_counts.get(1, 0), value_counts.get(0, 0)]\n",
    "    n = len(data)\n",
    "\n",
    "    # Berechne die erwarteten Werte\n",
    "    expected_values = [n*p, n*(1-p)]\n",
    "\n",
    "    # Überprüfe, ob die beobachteten Werte den erwarteten Werten entsprechen\n",
    "    if abs(observed_values[0] - expected_values[0]) / n < 0.05 and abs(observed_values[1] - expected_values[1]) / n < 0.05:\n",
    "        result = f'Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Binomial-Verteilung.'\n",
    "    else:\n",
    "        result = f'Die Daten in der Spalte {column_name} folgen wahrscheinlich nicht einer Binomial-Verteilung.'\n",
    "\n",
    "    with open(\"data/reports_data/binomial_distribution.txt\", \"w\") as f:\n",
    "        f.write(result)\n",
    "\n",
    "for column_name in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "        test_bernoulli_distribution(df[column_name], column_name, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::warning::Die Daten in der Spalte 5_o_Clock_Shadow folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Arched_Eyebrows folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Attractive folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Bags_Under_Eyes folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Bald folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Bangs folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Big_Lips folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Big_Nose folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Black_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Blond_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Blurry folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Brown_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Bushy_Eyebrows folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Chubby folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Double_Chin folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Eyeglasses folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Goatee folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Gray_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Heavy_Makeup folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte High_Cheekbones folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Male folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Mouth_Slightly_Open folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Mustache folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Narrow_Eyes folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte No_Beard folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Oval_Face folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Pale_Skin folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Pointy_Nose folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Receding_Hairline folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Rosy_Cheeks folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Sideburns folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Smiling folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Straight_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wavy_Hair folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wearing_Earrings folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wearing_Hat folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wearing_Lipstick folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wearing_Necklace folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Wearing_Necktie folgen wahrscheinlich nicht einer Binomialverteilung.\n",
      "::warning::Die Daten in der Spalte Young folgen wahrscheinlich nicht einer Binomialverteilung.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# def test_binomial_distribution(data, column_name, p):\n",
    "#     # Berechne die erwarteten Häufigkeiten\n",
    "#     data = data.replace(-1, 0)  \n",
    "#     n = len(data)\n",
    "#     expected_values = [n*p, n*(1-p)]\n",
    "#     value_counter = data.value_counts()\n",
    "#     # Berechne die beobachteten Häufigkeiten\n",
    "#     observed_values = [value_counter.get(1,0), value_counter.get(0,0)] # Zähle die Anzahl der Erfolge und Misserfolge\n",
    "    \n",
    "#     # Führe den Binomialtest durch\n",
    "#     p_value = binom\n",
    "\n",
    "#     # Überprüfe das Ergebnis\n",
    "#     if p_value > 0.05:\n",
    "#         print(f'::warning::Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Binomialverteilung.')\n",
    "#         with open(\"data/report_data/binomial_distribution.txt\", \"w\") as f:\n",
    "#             f.write(f'Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Binomialverteilung.') # Korrigiere den Schreibfehler\n",
    "#     else:\n",
    "#         print(f'::warning::Die Daten in der Spalte {column_name} folgen wahrscheinlich nicht einer Binomialverteilung.')\n",
    "\n",
    "# # Call the function with your data\n",
    "# for column_name in df.columns:\n",
    "#     if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "#         test_binomial_distribution(df[column_name], column_name, p=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Daten auf Exponentialverteilung testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "def test_exponential_distribution(data, column_name):\n",
    "    stat, p_value = kstest(data, 'expon')\n",
    "    if p_value > 0.05:\n",
    "        result = f'Die Daten in der Spalte {column_name} folgen wahrscheinlich einer Exponentialverteilung.'\n",
    "    else:\n",
    "        result = f'Die Daten in der Spalte {column_name} folgen wahrscheinlich nicht einer Exponentialverteilung.'\n",
    "\n",
    "    with open(\"data/report_data/exponential_distribution.txt\", \"w\") as f:\n",
    "        f.write(result)\n",
    "\n",
    "for column_name in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "        # Entfernen Sie nicht-numerische Werte\n",
    "        data = df[column_name].dropna()\n",
    "        test_exponential_distribution(data, column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hier werden die Daten nun visualisiert. Dabei werden Datenvielfalt, Datenverteilung visualisiert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    outliers_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            Q1 = df[column_name].quantile(0.25)\n",
    "            Q3 = df[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = df[(df[column_name] < Q1 - 1.5 * IQR) | (df[column_name] > Q3 + 1.5 * IQR)]\n",
    "            if not outliers.empty:\n",
    "                outliers_report.append(f\"Die Spalte '{column_name}' hat Ausreißer. Anzahl: {len(outliers)}\")\n",
    "\n",
    "    return \"/n\".join(outliers_report)\n",
    "\n",
    "detect_outliers_iqr_all_columns(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    duplicates = df.duplicated()\n",
    "    if duplicates.any():\n",
    "        print(f\"Es gibt {duplicates.sum()} Duplikate in den Daten.\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Duplikate in den Daten.\")\n",
    "\n",
    "check_duplicates(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    null_values = df.isnull().sum()\n",
    "    if null_values.any():\n",
    "        print(f\"Es gibt Nullwerte in den Daten:\\n{null_values}\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Nullwerte in den Daten.\")\n",
    "\n",
    "check_null_values(csv_path=csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
