{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importieren der benötigten Bibliotheken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tqdm\n",
    "import glob\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydqc.data_compare as dc \n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, binom_test, kstest, uniform\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Datenpreparation für das ML-Modell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Extrahieren der Bildpfade aus dem Ordner img_align_celeba \n",
    "##### Dies wird gemacht um die Pfade aus der Source-CSV: list_attr_celeba.csv in der Spalte image_id mit den richtigen Pfaden zu ersetzen. Somit sind die Pfade den Bildern richtig zugeordnet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_csv = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\source_csv\\list_attr_celeba.csv\"\n",
    "csv_path=r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\local_image_path_Gender.csv\"\n",
    "source_train_path = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\train\"\n",
    "men_image_source_path_train = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\train\\men\"\n",
    "women_image_source_path_train = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\train\\women\"\n",
    "men_image_source_path_test = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\val\\men\"\n",
    "women_image_source_path_test = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\val\\women\"\n",
    "merged_csv_test = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\csv_sheets\\merged_df_test.csv\"\n",
    "merged_csv_train = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\model\\csv_sheets\\merged_df_train.csv\"\n",
    "required_directories = [source_train_path, women_image_source_path_test,men_image_source_path_test,men_image_source_path_train,women_image_source_path_train]\n",
    "\n",
    "\n",
    "# Hauptpfad zu den Bildern\n",
    "base_path = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\img_align_celeba\"\n",
    "\n",
    "# Extrahiert aus dem Source Pfad die Bildpfade\n",
    "def get_image_paths(source_path):\n",
    "    image_formats = ['*.jpg', '*.png', '*.gif', '*.jpeg']\n",
    "    image_paths = []\n",
    "    for format in image_formats:\n",
    "        image_paths.extend(glob.glob(os.path.join(source_path, format)))\n",
    "    return image_paths\n",
    "\n",
    "# Testet ob die Bilder in der CSV-Datei die richtigen Dateiendungen haben\n",
    "def test_image_extensions_in_csv(csv_path, column_name_of_image_paths=\"image_id\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Überprüfe, ob alle Werte in der Spalte 'image_id' auf Bilddateien verweisen\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    df['valid_extension'] = df[column_name_of_image_paths].apply(lambda x: os.path.splitext(x)[1].lower() in valid_extensions)\n",
    "\n",
    "    # Drucke die Zeilennummern mit ungültiger Dateierweiterung, wenn es welche gibt\n",
    "    invalid_rows = df[~df['valid_extension']].index\n",
    "    if len(invalid_rows) > 0:\n",
    "        print(f'Ungültige Dateierweiterungen gefunden in den Zeilen: {invalid_rows.tolist()}')\n",
    "\n",
    "    assert all(df['valid_extension']), f'Nicht alle Werte in der Spalte {column_name_of_image_paths} verweisen auf Bilddateien.\\n {invalid_rows} \\n Überprüfe die Dateierweiterungen.'\n",
    "\n",
    "# Extrahieren der Bildpfade auf img_align_celeba\n",
    "image_paths_array = get_image_paths(base_path)\n",
    "\n",
    "# Erstellen eines Dataframes mit der Source CSV \n",
    "df = pd.read_csv(r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\source_csv\\list_attr_celeba.csv\")\n",
    "\n",
    "# Alte image_id Spalte löschen.\n",
    "df = df.drop(columns=[\"image_id\"])\n",
    "\n",
    "# Pfade aus image_id zu einer liste machen\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "\n",
    "# base_path mit image_paths_array verbinden\n",
    "join = pd.Series(image_paths_array).apply(lambda x: os.path.join(base_path, x))\n",
    "\n",
    "\n",
    "df[\"image_id\"] = join\n",
    "\n",
    "\n",
    "# \\ durch / ersetzen damit die Pfade richtig angeben werden\n",
    "df['image_id'] = df['image_id'].str.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Get a list of the column names\n",
    "cols = df.columns.tolist()\n",
    "\n",
    "# Spalte image_id an den Anfang setzen\n",
    "cols.insert(0, cols.pop(cols.index('image_id')))\n",
    "\n",
    "# Reindexieren des Dataframes\n",
    "df = df.reindex(columns=cols)\n",
    "\n",
    "# Speichern der neuen CSV\n",
    "df.to_csv(r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\source_csv\\list_attr_celeba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Testen ob die Bildpfade in der CSV-Datei die richtige Dateiendung haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\source_csv\\list_attr_celeba.csv\"\n",
    "test_image_extensions_in_csv(csv_path=csv_path, column_name_of_image_paths=\"image_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Überprüfen ob die Source_CSV im Dateiformat CSV ist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csv_extension(csv_path):\n",
    "    _, ext = os.path.splitext(csv_path)\n",
    "    assert ext.lower() == '.csv', f'Die Datei {csv_path} hat keine .csv Erweiterung'\n",
    "    \n",
    "check_csv_extension(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Überprüfen ob die benötigten Ordner vorhanden sind zum trainieren, testen, speichern der ML-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_directories_data_exists(directories):\n",
    "    for directory in directories:\n",
    "        assert os.path.isdir(directory), f'Das Verzeichnis {directory} existiert nicht'\n",
    "\n",
    "check_required_directories_data_exists(required_directories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Datenqualität testen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Überprüfen ob Bilddateien fehlen, Duplicate vorhanden sind, Überprüfen ob die Bildpfade gültig sind in der CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_quality_of_csv(csv_path,column_name_of_image_paths=\"image_id\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Überprüfe auf fehlende Werte\n",
    "    assert df[column_name_of_image_paths].isnull().sum() == 0, f'Es gibt fehlende Werte in der Spalte {column_name_of_image_paths}'\n",
    "\n",
    "    # Überprüfe auf Duplikate\n",
    "    assert df.duplicated().sum() == 0, \"Es gibt Duplikate in der Daten\"\n",
    "    \n",
    "    # Überprüfe, ob alle Werte in der Spalte 'image_id' gültige Bildpfade sind\n",
    "    assert all(df[column_name_of_image_paths].apply(os.path.isfile)), f'Nicht alle Werte in der Spalte {column_name_of_image_paths} sind gültige Bildpfade.\\n {df[column_name_of_image_paths].sample(10)} \\n Überprüfe, ob der Pfad vorhanden ist.' \n",
    "\n",
    "test_quality_of_csv(source_csv, column_name_of_image_paths=df.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Überprüfen ob es in allen Spalten Werte gibt die null bzw. leer sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    missing_values = df.isnull().any()\n",
    "    \n",
    "    return missing_values\n",
    "\n",
    "check_missing_values(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Überprüfen ob es Anomalien, Ausreißer gibt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_outliers_all_columns(csv_path):\n",
    "#     df = pd.read_csv(csv_path)\n",
    "#     for column_name in df.columns:\n",
    "#         if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "#             z_scores = np.abs((df[column_name] - df[column_name].mean()) / df[column_name].std())\n",
    "#             assert not any(z_scores > 3), f\"Es gibt Ausreißer in der Spalte '{column_name}'\"\n",
    "\n",
    "# test_outliers_all_columns(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Überprüfen ob die Daten ausgeglichen sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    imbalance_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            if abs(counts.get(-1, 0) - counts.get(1, 0)) >= 0.1 * len(df):\n",
    "                imbalance_report.append(f\"Die Spalte '{column_name}' ist unausgeglichen. Anzahl von -1: {counts.get(-1, 0)}, Anzahl von 1: {counts.get(1, 0)}\")\n",
    "\n",
    "    if imbalance_report:\n",
    "        print(\"Es gibt unausgeglichene Spalten:\\n\" + \"\\n\".join(imbalance_report))\n",
    "\n",
    "\n",
    "def plot_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            counts.plot(kind='bar', title=f\"Verteilung der Werte in der Spalte '{column_name}'\")\n",
    "            plt.show()\n",
    "        \n",
    "test_balance_all_columns(source_csv)\n",
    "plot_balance_all_columns(source_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Datensatz auf Ausreißer überprüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5_o_Clock_Shadow': 11.113579040370388,\n",
       " 'Arched_Eyebrows': 0.0,\n",
       " 'Attractive': 0.0,\n",
       " 'Bags_Under_Eyes': 20.457159215988234,\n",
       " 'Bald': 2.244334868385333,\n",
       " 'Bangs': 15.157527924619568,\n",
       " 'Big_Lips': 24.079585782753124,\n",
       " 'Big_Nose': 23.453225336748947,\n",
       " 'Black_Hair': 23.925093411122464,\n",
       " 'Blond_Hair': 14.799184596172735,\n",
       " 'Blurry': 5.089857304330229,\n",
       " 'Brown_Hair': 20.519351033321982,\n",
       " 'Bushy_Eyebrows': 14.216753290983666,\n",
       " 'Chubby': 5.756691790186526,\n",
       " 'Double_Chin': 4.668828572697793,\n",
       " 'Eyeglasses': 6.511878143524894,\n",
       " 'Goatee': 6.276437692189991,\n",
       " 'Gray_Hair': 4.1949861549168554,\n",
       " 'Heavy_Makeup': 0.0,\n",
       " 'High_Cheekbones': 0.0,\n",
       " 'Male': 0.0,\n",
       " 'Mouth_Slightly_Open': 0.0,\n",
       " 'Mustache': 4.154512115064734,\n",
       " 'Narrow_Eyes': 11.514864337928618,\n",
       " 'No_Beard': 16.506004471887817,\n",
       " 'Oval_Face': 0.0,\n",
       " 'Pale_Skin': 4.294690496991594,\n",
       " 'Pointy_Nose': 0.0,\n",
       " 'Receding_Hairline': 7.977828123534667,\n",
       " 'Rosy_Cheeks': 6.572095617451221,\n",
       " 'Sideburns': 5.6510644178895255,\n",
       " 'Smiling': 0.0,\n",
       " 'Straight_Hair': 20.840181837027824,\n",
       " 'Wavy_Hair': 0.0,\n",
       " 'Wearing_Earrings': 18.89249206560743,\n",
       " 'Wearing_Hat': 4.846025893513788,\n",
       " 'Wearing_Lipstick': 0.0,\n",
       " 'Wearing_Necklace': 12.296704327267163,\n",
       " 'Wearing_Necktie': 7.271506769529958,\n",
       " 'Young': 22.638315095336107}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_all_outliers(df):\n",
    "    outliers_percentage = {}\n",
    "    \n",
    "    # Gehe durch jede Spalte im DataFrame\n",
    "    for column_name in df.columns:\n",
    "        # Überspringe nicht-numerische Spalten\n",
    "        if pd.api.types.is_numeric_dtype(df[column_name]):\n",
    "            # Berechne den IQR-Score\n",
    "            Q1 = df[column_name].quantile(0.25)\n",
    "            Q3 = df[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "\n",
    "            # Definiere die Grenzen für Ausreißer\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "            # Finde die Ausreißer\n",
    "            outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "            \n",
    "            # Berechne den Prozentsatz der Ausreißer\n",
    "            outliers_percentage[column_name] = len(outliers) / len(df) * 100\n",
    "    \n",
    "    return outliers_percentage\n",
    "\n",
    "\n",
    "def detect_outliers(df, column_name):\n",
    "    # Berechne den IQR-Score\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Definiere die Grenzen für Ausreißer\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Finde die Ausreißer\n",
    "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "\n",
    "    return outliers\n",
    "\n",
    "\n",
    "df = pd.read_csv(source_csv)\n",
    "detect_all_outliers(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Unausgeglichenheit der Daten von ein Paar Datensätzen auflösen um das Verhalten auf das ML-Modell zu beobachten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Anpassen der Unausgeglichenheit zwischen Frauen und Mann Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gender_histogram(df):\n",
    "    # Zähle die Anzahl von Frauen und Männern\n",
    "    counts = df['Male'].value_counts()\n",
    "\n",
    "    # Plotte die Daten\n",
    "    plt.bar(['Female', 'Male'], [counts[-1], counts[1]], color=['#ff69b4', '#1f77b4'])\n",
    "\n",
    "    # Schreibe Text auf die Balken\n",
    "    for i, v in enumerate([counts[-1], counts[1]]):\n",
    "        plt.text(i, v, str(v), fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel('Gender')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def balance_column(csv_path, column_name):\n",
    "    # Lade die CSV-Datei in einen DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Zähle die Anzahl von -1 und 1\n",
    "    counts = df[column_name].value_counts()\n",
    "\n",
    "    # Finde den kleineren Wert\n",
    "    min_count = min(counts.get(-1, 0), counts.get(1, 0))\n",
    "\n",
    "    # Erstelle einen neuen DataFrame mit einer ausgeglichenen Anzahl von -1 und 1\n",
    "    df_balanced = pd.concat([\n",
    "        df[df[column_name] == -1].sample(min_count),\n",
    "        df[df[column_name] == 1].sample(min_count)\n",
    "    ], axis=0)\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "\n",
    "# Call the function with your csv file\n",
    "balanced_df = balance_column(source_csv, \"Male\")\n",
    "balanced_df.to_csv(\"balanced_gender.csv\", index=False)\n",
    "\n",
    "balanced_csv_path =r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\balanced_gender.csv\"\n",
    "plot_gender_histogram(balanced_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Unausgeglichenheit zwischen Jungen und Alten Personendatensätzen ausgleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_young_histogram(df):\n",
    "    # Zähle die Anzahl von Frauen und Männern\n",
    "    counts = df[\"Young\"].value_counts()\n",
    "\n",
    "    # Plotte die Daten\n",
    "    plt.bar(['not Young', 'Young'], [counts[-1], counts[1]], color=['#ff69b4', '#1f77b4'])\n",
    "\n",
    "    # Schreibe Text auf die Balken\n",
    "    for i, v in enumerate([counts[-1], counts[1]]):\n",
    "        plt.text(i, v, str(v), fontsize=12, ha='center', va='bottom')\n",
    "    plt.title('Young oder nicht Young ohne Balanced Gender Data')\n",
    "    plt.xlabel('Young or not Young')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "young_balanced_csv = r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\balanced_young.csv\"\n",
    "df_young_balanced = balance_column(source_csv, \"Young\")\n",
    "df_young_balanced.to_csv(\"balanced_young.csv\", index=False)\n",
    "df_young_balanced = pd.read_csv(young_balanced_csv)\n",
    "\n",
    "plot_young_histogram(df_young_balanced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Datenverteilung Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_distribution(df, column_name):\n",
    "    # Extrahiere die Daten\n",
    "    data = df[column_name]\n",
    "\n",
    "    # Überprüfe auf Normalverteilung mit dem Shapiro-Wilk-Test\n",
    "    stat, p = shapiro(data)\n",
    "    if p > 0.05:\n",
    "        print(f'{column_name} follows Normal distribution')\n",
    "\n",
    "    # Überprüfe auf Binomialverteilung mit dem Binomial-Test\n",
    "    unique_counts = len(np.unique(data))\n",
    "    if unique_counts == 2:\n",
    "        successes = data.sum()\n",
    "        n = len(data)\n",
    "        p = binom_test(successes, n, 0.5)  # Nullhypothese: p = 0.5\n",
    "        if p > 0.05:\n",
    "            print(f'{column_name} follows Binomial distribution')\n",
    "\n",
    "    # Überprüfe auf Gleichverteilung mit dem Kolmogorov-Smirnov-Test\n",
    "    stat, p = kstest(data, 'uniform')\n",
    "    if p > 0.05:\n",
    "        print(f'{column_name} follows Uniform distribution')\n",
    "\n",
    "df = pd.read_csv(source_csv)\n",
    "# Call the function with your DataFrame and column name\n",
    "check_distribution(df, 'Young')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hier werden die Daten nun visualisiert. Dabei werden Datenvielfalt, Datenverteilung visualisiert. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    outliers_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            Q1 = df[column_name].quantile(0.25)\n",
    "            Q3 = df[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = df[(df[column_name] < Q1 - 1.5 * IQR) | (df[column_name] > Q3 + 1.5 * IQR)]\n",
    "            if not outliers.empty:\n",
    "                outliers_report.append(f\"Die Spalte '{column_name}' hat Ausreißer. Anzahl: {len(outliers)}\")\n",
    "\n",
    "    return \"\\n\".join(outliers_report)\n",
    "\n",
    "detect_outliers_iqr_all_columns(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    duplicates = df.duplicated()\n",
    "    if duplicates.any():\n",
    "        print(f\"Es gibt {duplicates.sum()} Duplikate in den Daten.\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Duplikate in den Daten.\")\n",
    "\n",
    "check_duplicates(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    null_values = df.isnull().sum()\n",
    "    if null_values.any():\n",
    "        print(f\"Es gibt Nullwerte in den Daten:\\n{null_values}\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Nullwerte in den Daten.\")\n",
    "\n",
    "check_null_values(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "context = DataContext('great_expectations.yml')\n",
    "\n",
    "# Load a batch of data\n",
    "batch = context.get_batch('my_datasource', 'my_expectation_suite', 'my_data')\n",
    "\n",
    "# Check if the data meets your expectations\n",
    "results = context.run_validation_operator('action_list_operator', assets_to_validate=[batch])\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
