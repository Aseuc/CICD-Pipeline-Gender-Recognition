{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import tqdm\n",
    "import glob\n",
    "import pytest\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydqc.data_compare as dc \n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Datenpreparation für das ML-Modell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zunächst muss ich die Daten aus dem Source-Ordner der Bilder in die entsprechenden Ordnerverteilen um Beispielsweise in PyTorch mit der Funktion Imagefolder auch arbeiten zu können.\n",
    "##### Hierfür schreiben ich zunächst eine Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path=r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\attribute_list_labels\\list_attr_celeba.csv\"\n",
    "\n",
    "\n",
    "def get_image_paths(source_path):\n",
    "    image_formats = ['*.jpg', '*.png', '*.gif', '*.jpeg']\n",
    "    image_paths = []\n",
    "    for format in image_formats:\n",
    "        image_paths.extend(glob.glob(os.path.join(source_path, format)))\n",
    "    return image_paths\n",
    "\n",
    "def replace_image_paths(csv_path, new_image_paths, image_id=\"image_id\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[image_id] = new_image_paths\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "def test_data_quality(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Überprüfe auf fehlende Werte\n",
    "    assert df['image_id'].isnull().sum() == 0, \"Es gibt fehlende Werte in der Spalte 'image_id'\"\n",
    "\n",
    "    # Überprüfe auf Duplikate\n",
    "    assert df.duplicated().sum() == 0, \"Es gibt Duplikate in der Daten\"\n",
    "\n",
    "    # Überprüfe, ob alle Werte in der Spalte 'image_id' gültige Bildpfade sind\n",
    "    assert all(df['image_id'].apply(os.path.isfile)), \"Nicht alle Werte in der Spalte 'image_id' sind gültige Bildpfade\"\n",
    "\n",
    "\n",
    "def check_missing_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    missing_values = df.isnull().any()\n",
    "    return missing_values\n",
    "\n",
    "def test_outliers_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            z_scores = np.abs((df[column_name] - df[column_name].mean()) / df[column_name].std())\n",
    "            assert not any(z_scores > 3), f\"Es gibt Ausreißer in der Spalte '{column_name}'\"\n",
    "\n",
    "def test_balance(csv_path, column_name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    counts = df[column_name].value_counts()\n",
    "    assert abs(counts[-1] - counts[1]) < 0.1 * len(df), f\"Die Spalte '{column_name}' ist unausgeglichen. Anzahl von -1: {counts[-1]}, Anzahl von 1: {counts[1]}\"\n",
    "\n",
    "def test_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    imbalance_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            if abs(counts.get(-1, 0) - counts.get(1, 0)) >= 0.1 * len(df):\n",
    "                imbalance_report.append(f\"Die Spalte '{column_name}' ist unausgeglichen. Anzahl von -1: {counts.get(-1, 0)}, Anzahl von 1: {counts.get(1, 0)}\")\n",
    "\n",
    "    assert not imbalance_report, \"Es gibt unausgeglichene Spalten:\\n\" + \"\\n\".join(imbalance_report)\n",
    "\n",
    "def plot_balance_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            counts = df[column_name].value_counts()\n",
    "            counts.plot(kind='bar', title=f\"Verteilung der Werte in der Spalte '{column_name}'\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "# check_missing_values(csv_path=r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\attribute_list_labels\\list_attr_celeba.csv\")\n",
    "# test_data_quality(csv_path=r\"C:\\Users\\busse\\Bachelorarbeit\\CICD-Pipeline-Gender-Recognition\\data\\attribute_list_labels\\list_attr_celeba.csv\")\n",
    "plot_balance_all_columns(csv_path=csv_path)\n",
    "test_balance_all_columns(csv_path=csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr_all_columns(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    outliers_report = []\n",
    "\n",
    "    for column_name in df.columns:\n",
    "        if np.issubdtype(df[column_name].dtype, np.number):  # Überprüfe, ob die Spalte numerisch ist\n",
    "            Q1 = df[column_name].quantile(0.25)\n",
    "            Q3 = df[column_name].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = df[(df[column_name] < Q1 - 1.5 * IQR) | (df[column_name] > Q3 + 1.5 * IQR)]\n",
    "            if not outliers.empty:\n",
    "                outliers_report.append(f\"Die Spalte '{column_name}' hat Ausreißer. Anzahl: {len(outliers)}\")\n",
    "\n",
    "    return \"\\n\".join(outliers_report)\n",
    "\n",
    "detect_outliers_iqr_all_columns(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    duplicates = df.duplicated()\n",
    "    if duplicates.any():\n",
    "        print(f\"Es gibt {duplicates.sum()} Duplikate in den Daten.\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Duplikate in den Daten.\")\n",
    "\n",
    "check_duplicates(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    null_values = df.isnull().sum()\n",
    "    if null_values.any():\n",
    "        print(f\"Es gibt Nullwerte in den Daten:\\n{null_values}\")\n",
    "    else:\n",
    "        print(\"Es gibt keine Nullwerte in den Daten.\")\n",
    "\n",
    "check_null_values(csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "context = DataContext('great_expectations.yml')\n",
    "\n",
    "# Load a batch of data\n",
    "batch = context.get_batch('my_datasource', 'my_expectation_suite', 'my_data')\n",
    "\n",
    "# Check if the data meets your expectations\n",
    "results = context.run_validation_operator('action_list_operator', assets_to_validate=[batch])\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
